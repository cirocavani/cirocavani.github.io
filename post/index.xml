<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ciro Cavani</title>
    <link>http://cirocavani.github.io/post/</link>
    <description>Recent content in Posts on Ciro Cavani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Wed, 01 Mar 2017 11:31:34 -0300</lastBuildDate>
    
	<atom:link href="http://cirocavani.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TensorFlow: Recomendação com ALS (Collaborative Filtering)</title>
      <link>http://cirocavani.github.io/post/tensorflow-recomendacao-com-als-collaborative-filtering/</link>
      <pubDate>Wed, 01 Mar 2017 11:31:34 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/tensorflow-recomendacao-com-als-collaborative-filtering/</guid>
      <description>Esse artigo é sobre a análise do ALS implementado no TensorFlow. O ALS é um método para fatoração de matriz usado como algoritmo de Collaborative Filtering em Sistemas de Recomendação. A análise consiste no treinamento e tuning desse algoritmo e a avaliação do erro final. Para comparação, o mesmo algoritmo é implementado com o Spark. A metodologia usada tem características peculiares de como a Recomendação e o ALS funcionam. O resultado mostra que o Spark tem performance melhor que o TensorFlow no erro final.</description>
    </item>
    
    <item>
      <title>TensorFlow no Jupyter (com notebooks)</title>
      <link>http://cirocavani.github.io/post/tensorflow-no-jupyter-com-notebooks/</link>
      <pubDate>Tue, 13 Sep 2016 21:13:26 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/tensorflow-no-jupyter-com-notebooks/</guid>
      <description>Esse tutorial é sobre o TensorFlow no Jupyter. A princípio, esse projeto pode ser usado para instalar automaticamente o Jupyter Notebook configurado com TensorFlow 0.10 e alguns notebooks de exemplo (tutoriais do TensorFlow). Outro objetivo é servir como base para criação de configurações customizadas isoladas (exemplo um ambiente extra para testar com TensorFlow GPU Python 3 com CUDA 8). O Jupyter é uma ferramenta excelente para testar ideias e prototipar rapidamente com TensorFlow.</description>
    </item>
    
    <item>
      <title>Compilação do TensorFlow 0.10 para Linux (com GPU)</title>
      <link>http://cirocavani.github.io/post/compilacao-do-tensorflow-0.10-para-linux-com-gpu/</link>
      <pubDate>Thu, 08 Sep 2016 22:06:49 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-tensorflow-0.10-para-linux-com-gpu/</guid>
      <description>Esse tutorial é sobre a construção do pacote do TensorFlow 0.10 para Linux com suporte a GPU. Para esse procedimento é usado o Docker com uma imagem do Ubuntu 16.04, GCC 5.4, Python 2.7, Cuda 8.0 (RC) e cuDNN 5.1. A motivação desse trabalho é usar o TensorFlow com as novas gerações de GPUs da Nvidia (Pascal). Um segundo objetivo é a criação de um pacote do TensorFlow com capacidades específicas (por exemplo, um &amp;ldquo;Compute Capability&amp;rdquo; específico).</description>
    </item>
    
    <item>
      <title>TensorFlow: Integração com BigData</title>
      <link>http://cirocavani.github.io/post/tensorflow-integracao-bigdata/</link>
      <pubDate>Mon, 22 Aug 2016 22:00:00 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/tensorflow-integracao-bigdata/</guid>
      <description>Esse artigo é sobre a criação de uma Aplicação com TensorFlow em que o treinamento é feito no YARN (Hadoop), o servidor de inferência é hospedado no Tsuru e as requisições são feitas por Aplicações Java/Scala. Esses são os desafios para colocar em produção na Globo.com aplicações de Inteligência Artificial. Nesse trabalho foram desenvolvidos projetos que são Provas de Conceito de como fazer essa Aplicação TensorFlow integrada com BigData (o código está disponível no GitHub).</description>
    </item>
    
    <item>
      <title>Otimização dos parâmetros do Spark ALS (Collaborative Filtering) usando MOE</title>
      <link>http://cirocavani.github.io/post/otimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe/</link>
      <pubDate>Thu, 24 Sep 2015 19:44:08 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/otimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe/</guid>
      <description>Esse tutorial é sobre otimização de parâmetros em modelos de machine learning. Para esse tutorial, a ferramenta utilizada é o MOE, Metric Optimization Engine, desenvolvido pelo Yelp que implementa o algoritmo de busca usando Gaussian Process. O algoritmo escolhido para ter os parâmetros otimizados é o Collaborative Filtering baseado na fatoração da matriz de preferências. De forma genérica, esse é um processo que pode ser facilmente adaptado para outros algoritmos e permite sistematizar a árdua tarefa de escolher os melhores parâmetros para um modelo.</description>
    </item>
    
    <item>
      <title>Configuração do Hadoop, HBase e Kafka na Máquina Local com Docker</title>
      <link>http://cirocavani.github.io/post/configuracao-do-hadoop-hbase-e-kafka-na-maquina-local-com-docker/</link>
      <pubDate>Wed, 16 Sep 2015 23:26:07 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/configuracao-do-hadoop-hbase-e-kafka-na-maquina-local-com-docker/</guid>
      <description>Esse tutorial é sobre a criação de uma imagem do Docker com a configuração local do Hadoop, HBase e Kafka. Nesse procedimento, o Hadoop é configurado no modo pseudo-distribuído com cada serviço rodando em uma instância própria da JVM, mas todas na mesma máquina. O HBase e o Kafka também rodam em modo &amp;lsquo;distribuído&amp;rsquo; compartilhando uma instância separada do ZooKeeper. Esse procedimento é muito útil para testar funcionalidades desses serviços e aprendizado, mas não é uma solução completa para uso em produção.</description>
    </item>
    
    <item>
      <title>Compilação do Spark 1.5 (com bugfix)</title>
      <link>http://cirocavani.github.io/post/compilacao-do-spark-15-com-bugfix/</link>
      <pubDate>Fri, 11 Sep 2015 08:10:00 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-spark-15-com-bugfix/</guid>
      <description>Aproveitando que foi feito o lançamento da versão 1.5.0 do Spark, esse tutorial é sobre a construção do pacote do Spark usando o branch atualizado. O branch foi criado para fazer a estabilização do código que deu origem ao primeiro release. Esse branch continua recebendo atualizações importantes que farão parte de releases bugfix no futuro. Com esse procedimento, é possível gerar o pacote com essas últimas atualizações (e até customizar com alterações próprias) antecipando correções que podem ajudar em produção.</description>
    </item>
    
    <item>
      <title>Compilação do Hadoop para CentOS6 / RHEL6 usando Docker</title>
      <link>http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</link>
      <pubDate>Mon, 31 Aug 2015 22:45:23 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</guid>
      <description>Esse tutorial é sobre a construção do pacote do Hadoop 2.7.1 para o CentOS6 / RHEL6 usando Docker. Esse procedimento é necessário para gerar as bibliotecas nativas compatíveis. O principal objetivo que motivou esse trabalho foi configurar o FairScheduler do YARN usando CGroups rodando no Red Hat Enterprise Linux 6 (RHEL6). O pacote Hadoop distribuído pela Apache tem executável binário que não é compatível com a Glibc que faz parte do CentOS6/RHEL6.</description>
    </item>
    
    <item>
      <title>BigData na Globo.com</title>
      <link>http://cirocavani.github.io/post/bigdata-na-globocom/</link>
      <pubDate>Thu, 27 Aug 2015 06:00:00 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/bigdata-na-globocom/</guid>
      <description>A proposta desse artigo é fundamentar alguns conceitos de BigData e explorar a dinâmica de como tratar um grande volume de dados para extrair valor. A ideia é apresentar a solução de dados na Plataforma de BigData da Globo.com usada pelo Sistema de Recomendação e comentar a experiência do seu desenvolvimento.
Esse artigo é uma atualização e expansão da palestra realizada no Rio BigData Meetup em 21 de Outubro de 2014.</description>
    </item>
    
  </channel>
</rss>