<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Ciro Cavani</title>
    <link>http://cirocavani.github.io/tags/docker/</link>
    <description>Recent content in Docker on Ciro Cavani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Thu, 08 Sep 2016 22:06:49 -0300</lastBuildDate>
    <atom:link href="http://cirocavani.github.io/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Compilação do TensorFlow 0.10 para Linux (com GPU)</title>
      <link>http://cirocavani.github.io/post/compilacao-do-tensorflow-0.10-para-linux-com-gpu/</link>
      <pubDate>Thu, 08 Sep 2016 22:06:49 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-tensorflow-0.10-para-linux-com-gpu/</guid>
      <description>

&lt;p&gt;Esse tutorial é sobre a construção do pacote do TensorFlow 0.10 para Linux com suporte a GPU. Para esse procedimento é usado o Docker com uma imagem do Ubuntu 16.04, GCC 5.4, Python 2.7, Cuda 8.0 (RC) e cuDNN 5.1. A motivação desse trabalho é usar o TensorFlow com as novas gerações de GPUs da Nvidia (&lt;a href=&#34;https://developer.nvidia.com/pascal&#34;&gt;Pascal&lt;/a&gt;). Um segundo objetivo é a criação de um pacote do TensorFlow com capacidades específicas (por exemplo, um &amp;ldquo;Compute Capability&amp;rdquo; específico).&lt;/p&gt;

&lt;p&gt;O procedimento também está disponível como um script para Docker (ainda é necessário fazer o download do Cuda manualmente).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/cirocavani/tensorflow-build&#34;&gt;https://github.com/cirocavani/tensorflow-build&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;compilação&#34;&gt;Compilação&lt;/h2&gt;

&lt;p&gt;O procedimento consiste em:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Instalar o Cuda 8.0rc com o patch para GCC 5.4&lt;/li&gt;
&lt;li&gt;Instalar o cuDNN 5.1 para Cuda 8.0&lt;/li&gt;
&lt;li&gt;Instalar o Java 8&lt;/li&gt;
&lt;li&gt;Instalar o Bazel 0.3&lt;/li&gt;
&lt;li&gt;Construir TensorFlow 0.10&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;O resultado é o pacote do TensorFlow para Python 2 e Linux (com GPU):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow-0.10.0-py2-none-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Baseado na documentação:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#installing-from-sources&#34;&gt;https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#installing-from-sources&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Um procedimento alternativo:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/tools/docker/Dockerfile.devel-gpu&#34;&gt;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/tools/docker/Dockerfile.devel-gpu&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;download-do-cuda-8-0rc-cudnn-5-1&#34;&gt;Download do Cuda 8.0rc, cuDNN 5.1&lt;/h3&gt;

&lt;p&gt;É necessário o download dos pacotes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cuda_8.0.27_linux.run
cuda_8.0.27.1_linux.run
cudnn-8.0-linux-x64-v5.1.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Esses pacotes devem ser colocados na pasta &lt;code&gt;build_deps/&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;No momento, a versão mais recente do Cuda é a 8.0 RC e só está disponível para download para membros do &lt;a href=&#34;https://developer.nvidia.com/accelerated-computing-developer&#34;&gt;Accelerated Computing Developer Program&lt;/a&gt; no site da Nvidia (o cadastro é gratuito).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-release-candidate-download&#34;&gt;https://developer.nvidia.com/cuda-release-candidate-download&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Select Target Platform:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Operating System = Linux
Architecture = x86_64
Distribution = Ubuntu
Version = 16.04
Installer Type = runfile (local)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Base Installer&lt;/strong&gt; - &lt;code&gt;cuda_8.0.27_linux.run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Patch 1&lt;/strong&gt; - &lt;code&gt;cuda_8.0.27.1_linux.run&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/rdp/cudnn-download&#34;&gt;https://developer.nvidia.com/rdp/cudnn-download&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Selecione:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. I Agree To the Terms of the cuDNN Software License Agreement
2. Download cuDNN v5.1 (August 10, 2016), for CUDA 8.0 RC
3. cuDNN v5.1 Library for Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cudnn-8.0-linux-x64-v5.1.tgz&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;setup-inicial-no-docker-para-ubuntu-16-04&#34;&gt;Setup inicial no Docker para Ubuntu 16.04&lt;/h3&gt;

&lt;p&gt;Download dos demais pacotes necessários para o build:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd build_deps

curl -k -L \
  -H &amp;quot;Cookie: oraclelicense=accept-securebackup-cookie&amp;quot; \
  -O http://download.oracle.com/otn-pub/java/jdk/8u102-b14/jdk-8u102-linux-x64.tar.gz

curl -k -L \
  -O https://github.com/bazelbuild/bazel/releases/download/0.3.1/bazel-0.3.1-installer-linux-x86_64.sh

chmod +x cuda_8.0.27_linux.run
chmod +x cuda_8.0.27.1_linux.run
chmod +x bazel-0.3.1-installer-linux-x86_64.sh

cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Criação do Container com as dependências:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker create -t --name=tensorflow_build ubuntu:16.04
docker cp build_deps tensorflow_build:/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Execução do Shell no Container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker start tensorflow_build
docker exec -i -t tensorflow_build /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setup do Container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo &#39;debconf debconf/frontend select Noninteractive&#39; | debconf-set-selections
echo &#39;APT::Install-Recommends &amp;quot;0&amp;quot;;&#39; &amp;gt; 01norecommend
mv 01norecommend /etc/apt/apt.conf.d

apt-get update
apt-get upgrade -y

apt-get install -y \
    build-essential \
    python-dev \
    python-wheel \
    python-setuptools \
    python-numpy \
    swig \
    zlib1g-dev \
    unzip \
    file \
    git \
    ca-certificates \
    rsync
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;instalação-do-cuda-8-0rc-e-cudnn-5-1&#34;&gt;Instalação do Cuda 8.0rc e cuDNN 5.1&lt;/h3&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/build_deps/cuda_8.0.27_linux.run --silent --toolkit --override

/build_deps/cuda_8.0.27.1_linux.run --silent --accept-eula

tar zxf /build_deps/cudnn-8.0-linux-x64-v5.1.tgz \
    -C /usr/local/cuda-8.0 --strip-components=1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;instalação-do-java-8&#34;&gt;Instalação do Java 8&lt;/h3&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;tar zxf /build_deps/jdk-8u102-linux-x64.tar.gz -C /opt --no-same-owner

echo &#39;export JAVA_HOME=/opt/jdk1.8.0_102&#39; &amp;gt; /etc/profile.d/java.sh
echo &#39;export PATH=$PATH:$JAVA_HOME/bin&#39; &amp;gt;&amp;gt; /etc/profile.d/java.sh
chmod a+x /etc/profile.d/java.sh

source /etc/profile.d/java.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;instalação-do-bazel-0-3&#34;&gt;Instalação do Bazel 0.3&lt;/h3&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/build_deps/bazel-0.3.1-installer-linux-x86_64.sh --prefix=/opt/bazel-0.3.1

echo &#39;export PATH=$PATH:/opt/bazel-0.3.1/bin&#39; &amp;gt; /etc/profile.d/bazel.sh
chmod a+x /etc/profile.d/bazel.sh

source /etc/profile.d/bazel.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;construção-do-tensorflow-0-10&#34;&gt;Construção do TensorFlow 0.10&lt;/h3&gt;

&lt;p&gt;Considerações:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Configuração da GPU&lt;/p&gt;

&lt;p&gt;É necessário definir qual &amp;ldquo;Compute Capability&amp;rdquo; o binário do TensorFlow vai suportar.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-gpus&#34;&gt;https://developer.nvidia.com/cuda-gpus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Por exemplo:&lt;/p&gt;

&lt;p&gt;A GeForce GT 740M tem Compute Capability 3.0&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export TF_CUDA_COMPUTE_CAPABILITIES=3.0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Uso de Memória&lt;/p&gt;

&lt;p&gt;O build executa várias tarefas em paralelo e o consumo de memória pode aumentar rapidamente.&lt;/p&gt;

&lt;p&gt;Para limitar o número de execuções paralelas é usada a opção &lt;code&gt;-j 4&lt;/code&gt; no build.&lt;/p&gt;

&lt;p&gt;Em um notebook com 8 cores (HT), 8G de memória é insuficiente.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;useradd -m tensorflow
passwd -d tensorflow

su - tensorflow

git clone https://github.com/tensorflow/tensorflow.git -b r0.10 ~/tensorflow-0.10

cd ~/tensorflow-0.10

export PYTHON_BIN_PATH=/usr/bin/python
export TF_NEED_GCP=0
export TF_NEED_CUDA=1
export GCC_HOST_COMPILER_PATH=/usr/bin/gcc
export TF_CUDA_VERSION=8.0
export CUDA_TOOLKIT_PATH=/usr/local/cuda-8.0
export TF_CUDNN_VERSION=5
export CUDNN_INSTALL_PATH=/usr/local/cuda-8.0
export TF_CUDA_COMPUTE_CAPABILITIES=3.0
./configure

bazel build -j 4 -c opt --config=cuda \
    //tensorflow/tools/pip_package:build_pip_package

bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOME

mv ~/tensorflow-0.10.0-py2-none-{any,linux_x86_64}.whl

# saindo su
exit

# saindo do container
exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Para baixar o pacote (fora do container):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker cp \
    tensorflow_build:/home/tensorflow/tensorflow-0.10.0-py2-none-linux_x86_64.whl \
    .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusão&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;O procedimento de build do TensorFlow não é complicado, mas pequenas variações podem atingir alguns bugs do build (&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/3985&#34;&gt;exemplo&lt;/a&gt;). Com um script bem definido, fica fácil criar o pacote do TensorFlow.&lt;/p&gt;

&lt;p&gt;Com esse pacote, é possível usar o TensorFlow nas GPUs mais recentes da Nvidia.&lt;/p&gt;

&lt;p&gt;No próximo artigo será um tutorial de como configurar um ambiente de desenvolvimento com Jupyter.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Configuração do Hadoop, HBase e Kafka na Máquina Local com Docker</title>
      <link>http://cirocavani.github.io/post/configuracao-do-hadoop-hbase-e-kafka-na-maquina-local-com-docker/</link>
      <pubDate>Wed, 16 Sep 2015 23:26:07 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/configuracao-do-hadoop-hbase-e-kafka-na-maquina-local-com-docker/</guid>
      <description>

&lt;p&gt;Esse tutorial é sobre a criação de uma imagem do Docker com a configuração local do Hadoop, HBase e Kafka. Nesse procedimento, o Hadoop é configurado no modo pseudo-distribuído com cada serviço rodando em uma instância própria da JVM, mas todas na mesma máquina. O HBase e o Kafka também rodam em modo &amp;lsquo;distribuído&amp;rsquo; compartilhando uma instância separada do ZooKeeper. Esse procedimento é muito útil para testar funcionalidades desses serviços e aprendizado, mas não é uma solução completa para uso em produção.&lt;/p&gt;

&lt;h2 id=&#34;pré-requisito&#34;&gt;Pré-requisito&lt;/h2&gt;

&lt;p&gt;Nesse procedimento, é necessário que o Docker esteja instalado e funcionando; também é necessário acesso à Internet.&lt;/p&gt;

&lt;p&gt;Originalmente, esse procedimento foi testado no ArchLinux atualizado até final de Agosto/2015.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.archlinux.org/index.php/Docker&#34;&gt;https://wiki.archlinux.org/index.php/Docker&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker version

&amp;gt; Client:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&amp;gt;
&amp;gt; Server:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuração&#34;&gt;Configuração&lt;/h2&gt;

&lt;p&gt;Hadoop, ZooKeeper, HBase e Kafka.&lt;/p&gt;

&lt;h3 id=&#34;container&#34;&gt;Container&lt;/h3&gt;

&lt;p&gt;Começamos com a criação de um conainer do Docker com a imagem do CentOS6.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Importante: para os endereços com &lt;code&gt;grandesdados-hadoop&lt;/code&gt; funcionarem fora do container, direto na máquina host, é necessário colocar no &lt;code&gt;/etc/hosts&lt;/code&gt; da máquina host o endereço IP do container do Docker para esse nome.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ao executar o comando &lt;code&gt;run&lt;/code&gt;, o Docker automaticamente fará o download da imagem e a shell será inicializada dentro de um novo container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker run -i -t --name=grandesdados-hadoop --hostname=grandesdados-hadoop centos:6 /bin/bash

&amp;gt; Unable to find image &#39;centos:6&#39; locally
&amp;gt; 6: Pulling from library/centos
&amp;gt;
&amp;gt; f1b10cd84249: Pull complete
&amp;gt; fb9cc58bde0c: Pull complete
&amp;gt; a005304e4e74: Already exists
&amp;gt; library/centos:6: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.
&amp;gt;
&amp;gt; Digest: sha256:25d94c55b37cb7a33ad706d5f440e36376fec20f59e57d16fe02c64698b531c1
&amp;gt; Status: Downloaded newer image for centos:6
&amp;gt; [root@grandesdados-hadoop /]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Já dentro do container criamos um usuário e local que serão usados para a instalação e execução dos processos.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;adduser -m -d /hadoop hadoop
cd hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A versão usada nesse procedimento é o Java 8, atual versão estável da Oracle.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -k -L -H &amp;quot;Cookie: oraclelicense=accept-securebackup-cookie&amp;quot; -O http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm
rpm -i jdk-8u60-linux-x64.rpm

echo &#39;export JAVA_HOME=&amp;quot;/usr/java/jdk1.8.0_60&amp;quot;&#39; &amp;gt; /etc/profile.d/java.sh
source /etc/profile.d/java.sh

echo $JAVA_HOME

&amp;gt; /usr/java/jdk1.8.0_60

java -version

&amp;gt; java version &amp;quot;1.8.0_60&amp;quot;
&amp;gt; Java(TM) SE Runtime Environment (build 1.8.0_60-b27)
&amp;gt; Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para completar o ambiente de execução, instalamos os serviços e bibliotecas necessárias.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yum install -y tar openssh-clients openssh-server rsync gzip zlib openssl fuse bzip2 snappy

&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(configuração do SSH para acesso sem senha)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;service sshd start
chkconfig sshd on

su - hadoop

ssh-keygen -C hadoop -P &#39;&#39; -f ~/.ssh/id_rsa
cp ~/.ssh/{id_rsa.pub,authorized_keys}

ssh-keyscan grandesdados-hadoop &amp;gt;&amp;gt;  ~/.ssh/known_hosts
ssh-keyscan localhost &amp;gt;&amp;gt; ~/.ssh/known_hosts
ssh-keyscan 127.0.0.1 &amp;gt;&amp;gt; ~/.ssh/known_hosts
ssh-keyscan 0.0.0.0 &amp;gt;&amp;gt; ~/.ssh/known_hosts

ssh grandesdados-hadoop

&amp;gt; Warning: Permanently added the RSA host key for IP address &#39;172.17.0.12&#39; to the list of known hosts.
&amp;gt; (nova shell, sem login nem confirmação)

# (sair do shell do ssh)
exit
# (sair do shell do su)
exit

whoami

&amp;gt; root
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;hadoop&#34;&gt;Hadoop&lt;/h3&gt;

&lt;p&gt;Procedimento para configuração local do Hadoop em modo pseudo-distribuído com uma JVM por serviço.&lt;/p&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/SingleCluster.html&#34;&gt;documentação do Hadoop&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Serviços:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HDFS: NameNode, SecondaryNameNode, DataNode&lt;/li&gt;
&lt;li&gt;YARN: ResouceManager, NodeManager&lt;/li&gt;
&lt;li&gt;MR: HistoryServer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Instalação&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;O pacote usado nesse procedimento é o Hadoop 2.7.1 para CentOS6 descrito outro &lt;a href=&#34;http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/&#34;&gt;artigo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Primeiramente, colocamos o pacote dentro do container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# (shell fora do container)
sudo docker cp hadoop-2.7.1.tar.gz grandesdados-hadoop:/hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;De volta ao container como usuário root.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;tar zxf hadoop-2.7.1.tar.gz -C /opt
chown hadoop:hadoop -R /opt/hadoop-2.7.1

echo &#39;export PATH=$PATH:/opt/hadoop-2.7.1/bin:/opt/hadoop-2.7.1/sbin&#39; &amp;gt; /etc/profile.d/hadoop.sh
source /etc/profile.d/hadoop.sh

hadoop version

&amp;gt; Hadoop 2.7.1
&amp;gt; Subversion Unknown -r Unknown
&amp;gt; Compiled by hadoop on 2015-09-01T00:30Z
&amp;gt; Compiled with protoc 2.5.0
&amp;gt; From source with checksum fc0a1a23fc1868e4d5ee7fa2b28a58a
&amp;gt; This command was run using /opt/hadoop-2.7.1/share/hadoop/common/hadoop-common-2.7.1.jar

mkdir -p /data/hadoop
chown hadoop:hadoop /data/hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Configuração&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para a configuração, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/core-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/data/hadoop&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://grandesdados-hadoop&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/hdfs-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.blocksize&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;8M&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/yarn-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/mapred-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.jobtracker.staging.root.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/user&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setup Inicial (antes da primeira inicialização).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;hdfs namenode -format

&amp;gt; 15/09/16 02:12:03 INFO namenode.NameNode: STARTUP_MSG:
&amp;gt; /************************************************************
&amp;gt; STARTUP_MSG: Starting NameNode
&amp;gt; STARTUP_MSG:   host = grandesdados-hadoop/172.17.0.12
&amp;gt; STARTUP_MSG:   args = [-format]
&amp;gt; STARTUP_MSG:   version = 2.7.1
&amp;gt; (...)
&amp;gt; INFO namenode.NameNode: createNameNode [-format]
&amp;gt; Formatting using clusterid: CID-5daa32a0-3ab6-405e-bfd2-05c0a6e1e7e6
&amp;gt; (...)
&amp;gt; INFO common.Storage: Storage directory /data/hadoop/dfs/name has been successfully formatted.
&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;HDFS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(como usuário hadoop &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;start-dfs.sh

&amp;gt; Starting namenodes on [grandesdados-hadoop]
&amp;gt; grandesdados-hadoop: starting namenode, logging to /opt/hadoop-2.7.1/logs/hadoop-hadoop-namenode-grandesdados-hadoop.out
&amp;gt; localhost: starting datanode, logging to /opt/hadoop-2.7.1/logs/hadoop-hadoop-datanode-grandesdados-hadoop.out
&amp;gt; Starting secondary namenodes [0.0.0.0]
&amp;gt; 0.0.0.0: starting secondarynamenode, logging to /opt/hadoop-2.7.1/logs/hadoop-hadoop-secondarynamenode-grandesdados-hadoop.out

# criação do diretório do usuário hadoop
hdfs dfs -mkdir -p /user/hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do Name Node:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:50070/&#34;&gt;http://grandesdados-hadoop:50070/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Data Node (vazia):&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:50075/&#34;&gt;http://grandesdados-hadoop:50075/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Secondary Name Node:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:50090/&#34;&gt;http://grandesdados-hadoop:50090/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;stop-dfs.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;YARN&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(como usuário hadoop &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;start-yarn.sh

&amp;gt; starting yarn daemons
&amp;gt; starting resourcemanager, logging to /opt/hadoop-2.7.1/logs/yarn-hadoop-resourcemanager-grandesdados-hadoop.out
&amp;gt; localhost: starting nodemanager, logging to /opt/hadoop-2.7.1/logs/yarn-hadoop-nodemanager-grandesdados-hadoop.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do Resource Manager:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:8088/&#34;&gt;http://grandesdados-hadoop:8088/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Node Manager:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:8042/&#34;&gt;http://grandesdados-hadoop:8042/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;stop-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;History Server&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(como usuário hadoop &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mr-jobhistory-daemon.sh start historyserver

&amp;gt; starting historyserver, logging to /opt/hadoop-2.7.1/logs/mapred-hadoop-historyserver-grandesdados-hadoop.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do History Server:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:19888/&#34;&gt;http://grandesdados-hadoop:19888/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mr-jobhistory-daemon.sh stop historyserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processos:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x

&amp;gt;   PID TTY      STAT   TIME COMMAND
&amp;gt;  5162 ?        S      0:00 -bash
&amp;gt;  5327 ?        Sl     0:08 /usr/java/jdk1.8.0_60/bin/java -Dproc_namenode (...)
&amp;gt;  5423 ?        Sl     0:07 /usr/java/jdk1.8.0_60/bin/java -Dproc_datanode (...)
&amp;gt;  5612 ?        Sl     0:06 /usr/java/jdk1.8.0_60/bin/java -Dproc_secondarynamenode (...)
&amp;gt;  5772 ?        Sl     0:08 /usr/java/jdk1.8.0_60/bin/java -Dproc_resourcemanager (...)
&amp;gt;  5870 ?        Sl     0:07 /usr/java/jdk1.8.0_60/bin/java -Dproc_nodemanager (...)
&amp;gt;  6189 ?        Sl     0:08 /usr/java/jdk1.8.0_60/bin/java -Dproc_historyserver (...)
&amp;gt;  6273 ?        R+     0:00 ps x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Exemplos de MapReduce:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yarn jar /opt/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar

&amp;gt; An example program must be given as the first argument.
&amp;gt; Valid program names are:
&amp;gt;   aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
&amp;gt;   aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
&amp;gt;   bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
&amp;gt;   dbcount: An example job that count the pageview counts from a database.
&amp;gt;   distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
&amp;gt;   grep: A map/reduce program that counts the matches of a regex in the input.
&amp;gt;   join: A job that effects a join over sorted, equally partitioned datasets
&amp;gt;   multifilewc: A job that counts words from several files.
&amp;gt;   pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
&amp;gt;   pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
&amp;gt;   randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
&amp;gt;   randomwriter: A map/reduce program that writes 10GB of random data per node.
&amp;gt;   secondarysort: An example defining a secondary sort to the reduce.
&amp;gt;   sort: A map/reduce program that sorts the data written by the random writer.
&amp;gt;   sudoku: A sudoku solver.
&amp;gt;   teragen: Generate data for the terasort
&amp;gt;   terasort: Run the terasort
&amp;gt;   teravalidate: Checking results of terasort
&amp;gt;   wordcount: A map/reduce program that counts the words in the input files.
&amp;gt;   wordmean: A map/reduce program that counts the average length of the words in the input files.
&amp;gt;   wordmedian: A map/reduce program that counts the median length of the words in the input files.
&amp;gt;   wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Rodando o Cálculo do Pi com MapReduce:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yarn jar /opt/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 16 100000

&amp;gt; Number of Maps  = 16
&amp;gt; Samples per Map = 100000
&amp;gt; (...)
&amp;gt; INFO impl.YarnClientImpl: Submitted application application_1442439610364_0001
&amp;gt; INFO mapreduce.Job: The url to track the job: http://grandesdados-hadoop:8088/proxy/application_1442439610364_0001/
&amp;gt; INFO mapreduce.Job: Running job: job_1442439610364_0001
&amp;gt; (...)
&amp;gt; Job Finished in 48.333 seconds
&amp;gt; Estimated value of Pi is 3.14157500000000000000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h3&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;https://zookeeper.apache.org/doc/r3.4.6/zookeeperStarted.html&#34;&gt;documentação do ZooKeeper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dentro do container como usuário root:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O http://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
tar zxf zookeeper-3.4.6.tar.gz -C /opt
chown hadoop:hadoop -R /opt/zookeeper-3.4.6

echo &#39;export PATH=$PATH:/opt/zookeeper-3.4.6/bin&#39; &amp;gt; /etc/profile.d/zookeeper.sh
source /etc/profile.d/zookeeper.sh

mkdir -p /data/zookeeper
chown hadoop:hadoop /data/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/zookeeper-3.4.6/conf/zoo.cfg&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;tickTime=6000
dataDir=/data/zookeeper
clientPort=2181
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicializando o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop
zkServer.sh start

&amp;gt; JMX enabled by default
&amp;gt; Using config: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
&amp;gt; Starting zookeeper ... STARTED
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;zkServer.sh stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x | grep zoo

&amp;gt; 8246 ?        Sl     0:00 /usr/java/jdk1.8.0_60/bin/java (...) org.apache.zookeeper.server.quorum.QuorumPeerMain (...)
&amp;gt; 8291 ?        S+     0:00 grep zoo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Telnet:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo &#39;ruok&#39; |  curl telnet://grandesdados-hadoop:2181

&amp;gt; imok
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cliente:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;zkCli.sh -server grandesdados-hadoop:2181

&amp;gt; Connecting to grandesdados-hadoop:2181
&amp;gt; ...
&amp;gt; [zk: grandesdados-hadoop:2181(CONNECTED) 0] ls /
&amp;gt; [zookeeper]
&amp;gt; [zk: grandesdados-hadoop:2181(CONNECTED) 1] help
&amp;gt; ZooKeeper -server host:port cmd args
&amp;gt; 	stat path [watch]
&amp;gt; 	set path data [version]
&amp;gt; 	ls path [watch]
&amp;gt; 	delquota [-n|-b] path
&amp;gt; 	ls2 path [watch]
&amp;gt; 	setAcl path acl
&amp;gt; 	setquota -n|-b val path
&amp;gt; 	history
&amp;gt; 	redo cmdno
&amp;gt; 	printwatches on|off
&amp;gt; 	delete path [version]
&amp;gt; 	sync path
&amp;gt; 	listquota path
&amp;gt; 	rmr path
&amp;gt; 	get path [watch]
&amp;gt; 	create [-s] [-e] path data acl
&amp;gt; 	addauth scheme auth
&amp;gt; 	quit
&amp;gt; 	getAcl path
&amp;gt; 	close
&amp;gt; 	connect host:port
&amp;gt; [zk: grandesdados-hadoop:2181(CONNECTED) 3] quit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;hbase&#34;&gt;HBase&lt;/h3&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;http://hbase.apache.org/book.html#quickstart&#34;&gt;documentação do HBase&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dentro do container como usuário root:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O http://archive.apache.org/dist/hbase/1.1.2/hbase-1.1.2-bin.tar.gz
tar zxf hbase-1.1.2-bin.tar.gz -C /opt
chown hadoop:hadoop -R /opt/hbase-1.1.2

echo &#39;export PATH=$PATH:/opt/hbase-1.1.2/bin&#39; &amp;gt; /etc/profile.d/hbase.sh
source /etc/profile.d/hbase.sh

mkdir -p /data/hbase/tmp
chown hadoop:hadoop -R /data/hbase
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hbase-1.1.2/conf/hbase-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs:///hbase&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/data/hbase/tmp&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;grandesdados-hadoop&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hbase-1.1.2/conf/hbase-env.sh&lt;/code&gt;:
&lt;br/&gt;(manter conteúdo original, só alterar os valores abaixo)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export HBASE_OPTS=&amp;quot;-XX:+UseConcMarkSweepGC -Djava.net.preferIPv4Stack=true&amp;quot;
export HBASE_MANAGES_ZK=false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicializando o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop
start-hbase.sh

&amp;gt; starting master, logging to /opt/hbase-1.1.2/bin/../logs/hbase-hadoop-master-grandesdados-hadoop.out
&amp;gt; Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0
&amp;gt; Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0
&amp;gt; starting regionserver, logging to /opt/hbase-1.1.2/bin/../logs/hbase-hadoop-1-regionserver-grandesdados-hadoop.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do Master:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:16010/&#34;&gt;http://grandesdados-hadoop:16010/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Region Server:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:16301/&#34;&gt;http://grandesdados-hadoop:16301/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;stop-hbase.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x | grep hbase

&amp;gt; 8790 ?        S      0:00 bash /opt/hbase-1.1.2/bin/hbase-daemon.sh --config /opt/hbase-1.1.2/bin/../conf foreground_start master
&amp;gt; 8804 ?        Sl     0:14 /usr/java/jdk1.8.0_60/bin/java -Dproc_master (...)
&amp;gt; 8915 ?        S      0:00 bash /opt/hbase-1.1.2/bin/hbase-daemon.sh --config /opt/hbase-1.1.2/bin/../conf foreground_start regionserver -D hbase.regionserver.port=16201 -D hbase.regionserver.info.port=16301
&amp;gt; 8929 ?        Sl     0:14 /usr/java/jdk1.8.0_60/bin/java -Dproc_regionserver (...)
&amp;gt; 9329 ?        S+     0:00 grep hbase
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cliente:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;hbase shell

&amp;gt; HBase Shell; enter &#39;help&amp;lt;RETURN&amp;gt;&#39; for list of supported commands.
&amp;gt; Type &amp;quot;exit&amp;lt;RETURN&amp;gt;&amp;quot; to leave the HBase Shell
&amp;gt; Version 1.1.2, rcc2b70cf03e3378800661ec5cab11eb43fafe0fc, Wed Aug 26 20:11:27 PDT 2015
&amp;gt;
&amp;gt; hbase(main):001:0&amp;gt; status
&amp;gt; 1 servers, 0 dead, 2.0000 average load
&amp;gt;
&amp;gt; hbase(main):002:0&amp;gt; help
&amp;gt; HBase Shell, version 1.1.2, rcc2b70cf03e3378800661ec5cab11eb43fafe0fc, Wed Aug 26 20:11:27 PDT 2015
&amp;gt; Type &#39;help &amp;quot;COMMAND&amp;quot;&#39;, (e.g. &#39;help &amp;quot;get&amp;quot;&#39; -- the quotes are necessary) for help on a specific command.
&amp;gt; Commands are grouped. Type &#39;help &amp;quot;COMMAND_GROUP&amp;quot;&#39;, (e.g. &#39;help &amp;quot;general&amp;quot;&#39;) for help on a command group.
&amp;gt; (...)
&amp;gt; hbase(main):004:0&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kafka&#34;&gt;Kafka&lt;/h3&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;http://kafka.apache.org/documentation.html#quickstart&#34;&gt;documentação do Kafka&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dentro do container como usuário root:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O http://archive.apache.org/dist/kafka/0.8.2.1/kafka_2.10-0.8.2.1.tgz
tar zxf kafka_2.10-0.8.2.1.tgz -C /opt
chown hadoop:hadoop -R /opt/kafka_2.10-0.8.2.1

echo &#39;export PATH=$PATH:/opt/kafka_2.10-0.8.2.1/bin&#39; &amp;gt; /etc/profile.d/kafka.sh
source /etc/profile.d/kafka.sh

mkdir -p /data/kafka
chown hadoop:hadoop /data/kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/kafka_2.10-0.8.2.1/config/server.properties&lt;/code&gt;:
&lt;br/&gt;(manter conteúdo original, só alterar os valores abaixo)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;log.dirs=/data/kafka
zookeeper.connect=grandesdados-hadoop:2181
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicializando o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop
kafka-server-start.sh /opt/kafka_2.10-0.8.2.1/config/server.properties &amp;amp;&amp;gt; kafka.out &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;kafka-server-stop.sh /opt/kafka_2.10-0.8.2.1/config/server.properties
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x | grep kafka

&amp;gt; 9818 ?        Sl     0:03 /usr/java/jdk1.8.0_60/bin/java (...) kafka.Kafka /opt/kafka_2.10-0.8.2.1/config/server.properties
&amp;gt; 9928 ?        S+     0:00 grep kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enviando e recebendo mensagens:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;kafka-topics.sh \
--create \
--zookeeper grandesdados-hadoop:2181 \
--replication-factor 1 \
--partitions 1 \
--topic test

&amp;gt; Created topic &amp;quot;test&amp;quot;.

echo &#39;Primeira mensagem de teste&#39; | kafka-console-producer.sh --broker-list grandesdados-hadoop:9092 --topic test

&amp;gt; (...)

kafka-console-consumer.sh --zookeeper grandesdados-hadoop:2181 --topic test --from-beginning

&amp;gt; Primeira mensagem de teste
&amp;gt; ^CConsumed 1 messages
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusão&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;A revolução em BigData é um fenômeno da tecnologia desenvolvida ao longo dos últimos anos focada na manipulação de um grande volume de dados em máquinas de baixo custo. Essa é a tecnologia que torna possível combinar uma solução de dados escalável com processos para geração de resultados relevantes, tanto no desenvolvimento de produtos quanto na evolução do conhecimento. O importante é entender como essa tecnologia pode ser usada para agregar valor ao negócio e permitir imaginar soluções inovadoras.&lt;/p&gt;

&lt;p&gt;Esse artigo documenta o passo-a-passo de uma configuração local do Hadoop, ZooKeeper, HBase e Kafka. Esses são os serviços essenciais em uma plataforma de BigData que, juntamente com o Spark, possibilitam o desenvolvimento de soluções tanto para processamento batch quanto para tempo real.&lt;/p&gt;

&lt;p&gt;Em artigos futuros, entrarei usando essa solução para desenvolver e testar algumas aplicações de BigData usando Spark.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compilação do Hadoop para CentOS6 / RHEL6 usando Docker</title>
      <link>http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</link>
      <pubDate>Mon, 31 Aug 2015 22:45:23 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</guid>
      <description>

&lt;p&gt;Esse tutorial é sobre a construção do pacote do Hadoop 2.7.1 para o CentOS6 / RHEL6 usando Docker. Esse procedimento é necessário para gerar as bibliotecas nativas compatíveis. O principal objetivo que motivou esse trabalho foi configurar o FairScheduler do YARN usando CGroups rodando no Red Hat Enterprise Linux 6 (RHEL6). O pacote Hadoop distribuído pela Apache tem executável binário que não é compatível com a Glibc que faz parte do CentOS6/RHEL6.&lt;/p&gt;

&lt;p&gt;O RHEL6 é o sistema operacional homologado para as máquinas do cluster que usamos na Globo.com e foi necessário criar uma distribuição própria do Hadoop para que pudéssemos fazer uso do &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/FairScheduler.html&#34;&gt;FairScheduler&lt;/a&gt; juntamente com o &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html&#34;&gt;CGroups&lt;/a&gt; para limitar o uso de processamento entre as aplicações rodando nos mesmos NodeManagers.&lt;/p&gt;

&lt;p&gt;Esse trabalho de configuração do Hadoop para uso compartilhado será assunto de outro artigo.&lt;/p&gt;

&lt;p&gt;Nesse artigo, o foco é um passo a passo de como usar o Docker para gerar um pacote do Hadoop adaptado para o Red Hat Enterprise Linux 6 (RHEL6) usando CentOS6.&lt;/p&gt;

&lt;h2 id=&#34;pré-requisito&#34;&gt;Pré-requisito&lt;/h2&gt;

&lt;p&gt;Nesse procedimento, é necessário que o Docker esteja instalado e funcionando; também é necessário acesso à Internet.&lt;/p&gt;

&lt;p&gt;Originalmente, esse procedimento foi testado no ArchLinux atualizado até final de Agosto/2015.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.archlinux.org/index.php/Docker&#34;&gt;https://wiki.archlinux.org/index.php/Docker&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker version

&amp;gt; Client:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&amp;gt;
&amp;gt; Server:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;compilação&#34;&gt;Compilação&lt;/h2&gt;

&lt;p&gt;Documento com instruções de build do Hadoop &lt;a href=&#34;https://github.com/apache/hadoop/blob/release-2.7.1/BUILDING.txt&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;O resultado desse procedimento é um pacote do Hadoop com os executáveis e bibliotecas nativas compilados para o CentOS6 que rodam no RHEL6.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Começamos com a criação de um conainer do Docker com a imagem do CentOS6.&lt;/p&gt;

&lt;p&gt;Ao executar o comando &lt;code&gt;run&lt;/code&gt;, o Docker automaticamente fará o download da imagem e a shell será inicializada dentro de um novo container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker run -i -t centos:6 /bin/bash

&amp;gt; Unable to find image &#39;centos:6&#39; locally
&amp;gt; 6: Pulling from library/centos
&amp;gt;
&amp;gt; f1b10cd84249: Pull complete
&amp;gt; fb9cc58bde0c: Pull complete
&amp;gt; a005304e4e74: Already exists
&amp;gt; library/centos:6: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.
&amp;gt;
&amp;gt; Digest: sha256:25d94c55b37cb7a33ad706d5f440e36376fec20f59e57d16fe02c64698b531c1
&amp;gt; Status: Downloaded newer image for centos:6
&amp;gt; [root@3cc2bc5e593b /]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Já dentro do container criamos um usuário e local que serão usados na compilação e geração do pacote.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;adduser -m -d /hadoop hadoop
cd hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para a compilação das bibliotecas nativas é necessária a instalação do compilador C e mais alguns pacotes de desenvolvimento (cabeçalhos das bibliotecas usadas pelo Hadoop).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yum install -y tar gzip gcc-c++ cmake zlib zlib-devel openssl openssl-devel fuse fuse-devel bzip2 bzip2-devel snappy snappy-devel

&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O Hadoop ainda depende de duas outras bibliotecas que precisam ser instaladas manualmente no CentOS: Google ProtoBuf 2.5 (RPC), Jansson (JSON).&lt;/p&gt;

&lt;p&gt;Para instalar o ProtoBuf, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
tar zxf protobuf-2.5.0.tar.gz
cd protobuf-2.5.0
./configure --prefix=/usr --libdir=/usr/lib64
make
make check
make install

cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para instalar o Jansson, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -O http://www.digip.org/jansson/releases/jansson-2.7.tar.gz
tar zxf jansson-2.7.tar.gz
cd jansson-2.7
./configure --prefix=/usr --libdir=/usr/lib64
make
make install

cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para completar o ambiente de compilação, precisamos do JDK e do Maven.&lt;/p&gt;

&lt;p&gt;No caso do JDK, usaremos o pacote RPM já disponibilizado pela Oracle.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -k -L -H &amp;quot;Cookie: oraclelicense=accept-securebackup-cookie&amp;quot; -O http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm
rpm -i jdk-8u60-linux-x64.rpm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No caso do Maven, usaremos o pacote binário de distribuição da Apache.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -O http://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz
tar zxf apache-maven-3.3.3-bin.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O ambiente  de compilação está completo.&lt;/p&gt;

&lt;p&gt;Agora estamos pronto para a compilação do Hadoop. Nesse caso, estaremos gerando o pacote de distribuição somente com o binário Java e as bibliotecas nativas.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop

export PATH=$PATH:/hadoop/apache-maven-3.3.3/bin

curl -O http://archive.apache.org/dist/hadoop/common/hadoop-2.7.1/hadoop-2.7.1-src.tar.gz
tar zxf hadoop-2.7.1-src.tar.gz
cd hadoop-2.7.1-src

mvn clean package -Pdist,native -DskipTests -Drequire.snappy -Drequire.openssl -Dtar

&amp;gt; (...)
&amp;gt; main:
&amp;gt;      [exec] $ tar cf hadoop-2.7.1.tar hadoop-2.7.1
&amp;gt;      [exec] $ gzip -f hadoop-2.7.1.tar
&amp;gt;      [exec]
&amp;gt;      [exec] Hadoop dist tar available at: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz
&amp;gt;      [exec]
&amp;gt; [INFO] Executed tasks
&amp;gt; [INFO]
&amp;gt; [INFO] --- maven-javadoc-plugin:2.8.1:jar (module-javadocs) @ hadoop-dist ---
&amp;gt; [INFO] Building jar: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-dist-2.7.1-javadoc.jar
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO]
&amp;gt; [INFO] Apache Hadoop Main ................................. SUCCESS [01:56 min]
&amp;gt; [INFO] Apache Hadoop Project POM .......................... SUCCESS [ 42.134 s]
&amp;gt; [INFO] Apache Hadoop Annotations .......................... SUCCESS [ 37.761 s]
&amp;gt; [INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.125 s]
&amp;gt; [INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [ 23.183 s]
&amp;gt; [INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 25.962 s]
&amp;gt; [INFO] Apache Hadoop MiniKDC .............................. SUCCESS [03:23 min]
&amp;gt; [INFO] Apache Hadoop Auth ................................. SUCCESS [02:11 min]
&amp;gt; [INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 10.145 s]
&amp;gt; [INFO] Apache Hadoop Common ............................... SUCCESS [03:29 min]
&amp;gt; [INFO] Apache Hadoop NFS .................................. SUCCESS [  4.724 s]
&amp;gt; [INFO] Apache Hadoop KMS .................................. SUCCESS [02:35 min]
&amp;gt; [INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.024 s]
&amp;gt; [INFO] Apache Hadoop HDFS ................................. SUCCESS [02:15 min]
&amp;gt; [INFO] Apache Hadoop HttpFS ............................... SUCCESS [02:13 min]
&amp;gt; [INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [ 38.598 s]
&amp;gt; [INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  3.213 s]
&amp;gt; [INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.032 s]
&amp;gt; [INFO] hadoop-yarn ........................................ SUCCESS [  0.030 s]
&amp;gt; [INFO] hadoop-yarn-api .................................... SUCCESS [ 29.193 s]
&amp;gt; [INFO] hadoop-yarn-common ................................. SUCCESS [02:02 min]
&amp;gt; [INFO] hadoop-yarn-server ................................. SUCCESS [  0.040 s]
&amp;gt; [INFO] hadoop-yarn-server-common .......................... SUCCESS [  8.499 s]
&amp;gt; [INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [ 12.283 s]
&amp;gt; [INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [  2.359 s]
&amp;gt; [INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [  5.298 s]
&amp;gt; [INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 15.095 s]
&amp;gt; [INFO] hadoop-yarn-server-tests ........................... SUCCESS [  3.772 s]
&amp;gt; [INFO] hadoop-yarn-client ................................. SUCCESS [  4.641 s]
&amp;gt; [INFO] hadoop-yarn-server-sharedcachemanager .............. SUCCESS [  2.433 s]
&amp;gt; [INFO] hadoop-yarn-applications ........................... SUCCESS [  0.019 s]
&amp;gt; [INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  1.884 s]
&amp;gt; [INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [  1.263 s]
&amp;gt; [INFO] hadoop-yarn-site ................................... SUCCESS [  0.020 s]
&amp;gt; [INFO] hadoop-yarn-registry ............................... SUCCESS [  3.532 s]
&amp;gt; [INFO] hadoop-yarn-project ................................ SUCCESS [  3.452 s]
&amp;gt; [INFO] hadoop-mapreduce-client ............................ SUCCESS [  0.036 s]
&amp;gt; [INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 15.195 s]
&amp;gt; [INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 12.459 s]
&amp;gt; [INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [  2.645 s]
&amp;gt; [INFO] hadoop-mapreduce-client-app ........................ SUCCESS [  6.342 s]
&amp;gt; [INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [  3.845 s]
&amp;gt; [INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 11.295 s]
&amp;gt; [INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  1.546 s]
&amp;gt; [INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  4.573 s]
&amp;gt; [INFO] hadoop-mapreduce ................................... SUCCESS [  2.164 s]
&amp;gt; [INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [  7.874 s]
&amp;gt; [INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [ 19.660 s]
&amp;gt; [INFO] Apache Hadoop Archives ............................. SUCCESS [  2.071 s]
&amp;gt; [INFO] Apache Hadoop Rumen ................................ SUCCESS [  3.966 s]
&amp;gt; [INFO] Apache Hadoop Gridmix .............................. SUCCESS [  3.215 s]
&amp;gt; [INFO] Apache Hadoop Data Join ............................ SUCCESS [  1.818 s]
&amp;gt; [INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [  1.478 s]
&amp;gt; [INFO] Apache Hadoop Extras ............................... SUCCESS [  2.037 s]
&amp;gt; [INFO] Apache Hadoop Pipes ................................ SUCCESS [  5.880 s]
&amp;gt; [INFO] Apache Hadoop OpenStack support .................... SUCCESS [  3.407 s]
&amp;gt; [INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [ 40.013 s]
&amp;gt; [INFO] Apache Hadoop Azure support ........................ SUCCESS [ 11.557 s]
&amp;gt; [INFO] Apache Hadoop Client ............................... SUCCESS [  7.659 s]
&amp;gt; [INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  0.042 s]
&amp;gt; [INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  3.072 s]
&amp;gt; [INFO] Apache Hadoop Tools Dist ........................... SUCCESS [  8.519 s]
&amp;gt; [INFO] Apache Hadoop Tools ................................ SUCCESS [  0.014 s]
&amp;gt; [INFO] Apache Hadoop Distribution ......................... SUCCESS [ 30.616 s]
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Total time: 29:26 min
&amp;gt; [INFO] Finished at: 2015-09-01T00:47:31+00:00
&amp;gt; [INFO] Final Memory: 224M/785M
&amp;gt; [INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para completar a compilação, executamos os testes, contudo, alguns deles podem apresentar falhas intermitentes (acontecem algumas vezes, outras não).&lt;/p&gt;

&lt;p&gt;Os testes podem levar algumas horas para rodar por completo.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir hadoop-common-project/hadoop-common/target/test-classes/webapps/test

mvn test -Pnative -Drequire.snappy -Drequire.openssl -Dmaven.test.failure.ignore=true -Dsurefire.rerunFailingTestsCount=3

&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(alguns testes com falha intermitente)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;org.apache.hadoop.ipc.TestDecayRpcScheduler#testAccumulate&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics#testDataNodeTimeSpend&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache#testDataXceiverHandlesRequestShortCircuitShmFailure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;No final desse procedimento, o pacote do Hadoop estará gerado em:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Para copiar do container para a máquina host:
&lt;br/&gt;(&lt;code&gt;3cc2bc5e593b&lt;/code&gt; é o identificador do container no Docker)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# shell na máquina
sudo docker cp 3cc2bc5e593b:/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusão&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;Esse procedimento mostra como o Hadoop pode ser customizado para necessidades específicas e que não requer um esforço muito grande.&lt;/p&gt;

&lt;p&gt;Contudo, ter uma &amp;ldquo;versão&amp;rdquo; própria do Hadoop é uma decisão que deve ser tomada com cautela.&lt;/p&gt;

&lt;p&gt;No momento, a gente considera que essa seja a melhor escolha para o nosso trabalho na Globo.com e estamos querendo formar um time para evoluir e dar suporte a essa plataforma. O maior benefício é a liberdade de escolher como configurar e melhorar nossa infraestrutura. O custo é não ter uma empresa especializada &amp;ldquo;cuidando&amp;rdquo; dessa responsabilidade.&lt;/p&gt;

&lt;p&gt;No futuro, pode ser que mudemos esse modo de operação e busquemos uma distribuição &amp;ldquo;profissional&amp;rdquo; como Cloudera, Hortonworks ou outra.&lt;/p&gt;

&lt;p&gt;Particularmente, eu prefiro manter uma plataforma própria.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>