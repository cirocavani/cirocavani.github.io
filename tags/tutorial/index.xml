<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on Ciro Cavani</title>
    <link>http://cirocavani.github.io/tags/tutorial/</link>
    <description>Recent content in Tutorial on Ciro Cavani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Thu, 08 Sep 2016 22:06:49 -0300</lastBuildDate>
    <atom:link href="http://cirocavani.github.io/tags/tutorial/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Compilação do TensorFlow 0.10 para Linux (com GPU)</title>
      <link>http://cirocavani.github.io/post/compilacao-do-tensorflow-0.10-para-linux-com-gpu/</link>
      <pubDate>Thu, 08 Sep 2016 22:06:49 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-tensorflow-0.10-para-linux-com-gpu/</guid>
      <description>

&lt;p&gt;Esse tutorial é sobre a construção do pacote do TensorFlow 0.10 para Linux com suporte a GPU. Para esse procedimento é usado o Docker com uma imagem do Ubuntu 16.04, GCC 5.4, Python 2.7, Cuda 8.0 (RC) e cuDNN 5.1. A motivação desse trabalho é usar o TensorFlow com as novas gerações de GPUs da Nvidia (&lt;a href=&#34;https://developer.nvidia.com/pascal&#34;&gt;Pascal&lt;/a&gt;). Um segundo objetivo é a criação de um pacote do TensorFlow com capacidades específicas (por exemplo, um &amp;ldquo;Compute Capability&amp;rdquo; específico).&lt;/p&gt;

&lt;p&gt;O procedimento também está disponível como um script para Docker (ainda é necessário fazer o download do Cuda manualmente).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/cirocavani/tensorflow-build&#34;&gt;https://github.com/cirocavani/tensorflow-build&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;compilação:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Compilação&lt;/h2&gt;

&lt;p&gt;O procedimento consiste em:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Instalar o Cuda 8.0rc com o patch para GCC 5.4&lt;/li&gt;
&lt;li&gt;Instalar o cuDNN 5.1 para Cuda 8.0&lt;/li&gt;
&lt;li&gt;Instalar o Java 8&lt;/li&gt;
&lt;li&gt;Instalar o Bazel 0.3&lt;/li&gt;
&lt;li&gt;Construir TensorFlow 0.10&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;O resultado é o pacote do TensorFlow para Python 2 e Linux (com GPU):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tensorflow-0.10.0-py2-none-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Baseado na documentação:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#installing-from-sources&#34;&gt;https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#installing-from-sources&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Um procedimento alternativo:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/tools/docker/Dockerfile.devel-gpu&#34;&gt;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/tools/docker/Dockerfile.devel-gpu&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;download-do-cuda-8-0rc-cudnn-5-1:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Download do Cuda 8.0rc, cuDNN 5.1&lt;/h3&gt;

&lt;p&gt;É necessário o download dos pacotes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cuda_8.0.27_linux.run
cuda_8.0.27.1_linux.run
cudnn-8.0-linux-x64-v5.1.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Esses pacotes devem ser colocados na pasta &lt;code&gt;build_deps/&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;No momento, a versão mais recente do Cuda é a 8.0 RC e só está disponível para download para membros do &lt;a href=&#34;https://developer.nvidia.com/accelerated-computing-developer&#34;&gt;Accelerated Computing Developer Program&lt;/a&gt; no site da Nvidia (o cadastro é gratuito).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-release-candidate-download&#34;&gt;https://developer.nvidia.com/cuda-release-candidate-download&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Select Target Platform:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Operating System = Linux
Architecture = x86_64
Distribution = Ubuntu
Version = 16.04
Installer Type = runfile (local)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Base Installer&lt;/strong&gt; - &lt;code&gt;cuda_8.0.27_linux.run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Patch 1&lt;/strong&gt; - &lt;code&gt;cuda_8.0.27.1_linux.run&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/rdp/cudnn-download&#34;&gt;https://developer.nvidia.com/rdp/cudnn-download&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Selecione:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. I Agree To the Terms of the cuDNN Software License Agreement
2. Download cuDNN v5.1 (August 10, 2016), for CUDA 8.0 RC
3. cuDNN v5.1 Library for Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cudnn-8.0-linux-x64-v5.1.tgz&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;setup-inicial-no-docker-para-ubuntu-16-04:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Setup inicial no Docker para Ubuntu 16.04&lt;/h3&gt;

&lt;p&gt;Download dos demais pacotes necessários para o build:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd build_deps

curl -k -L \
  -H &amp;quot;Cookie: oraclelicense=accept-securebackup-cookie&amp;quot; \
  -O http://download.oracle.com/otn-pub/java/jdk/8u102-b14/jdk-8u102-linux-x64.tar.gz

curl -k -L \
  -O https://github.com/bazelbuild/bazel/releases/download/0.3.1/bazel-0.3.1-installer-linux-x86_64.sh

chmod +x cuda_8.0.27_linux.run
chmod +x cuda_8.0.27.1_linux.run
chmod +x bazel-0.3.1-installer-linux-x86_64.sh

cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Criação do Container com as dependências:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker create -t --name=tensorflow_build ubuntu:16.04
docker cp build_deps tensorflow_build:/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Execução do Shell no Container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker start tensorflow_build
docker exec -i -t tensorflow_build /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setup do Container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo &#39;debconf debconf/frontend select Noninteractive&#39; | debconf-set-selections
echo &#39;APT::Install-Recommends &amp;quot;0&amp;quot;;&#39; &amp;gt; 01norecommend
mv 01norecommend /etc/apt/apt.conf.d

apt-get update
apt-get upgrade -y

apt-get install -y \
    build-essential \
    python-dev \
    python-wheel \
    python-setuptools \
    python-numpy \
    swig \
    zlib1g-dev \
    unzip \
    file \
    git \
    ca-certificates \
    rsync
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;instalação-do-cuda-8-0rc-e-cudnn-5-1:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Instalação do Cuda 8.0rc e cuDNN 5.1&lt;/h3&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/build_deps/cuda_8.0.27_linux.run --silent --toolkit --override

/build_deps/cuda_8.0.27.1_linux.run --silent --accept-eula

tar zxf /build_deps/cudnn-8.0-linux-x64-v5.1.tgz \
    -C /usr/local/cuda-8.0 --strip-components=1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;instalação-do-java-8:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Instalação do Java 8&lt;/h3&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;tar zxf /build_deps/jdk-8u102-linux-x64.tar.gz -C /opt --no-same-owner

echo &#39;export JAVA_HOME=/opt/jdk1.8.0_102&#39; &amp;gt; /etc/profile.d/java.sh
echo &#39;export PATH=$PATH:$JAVA_HOME/bin&#39; &amp;gt;&amp;gt; /etc/profile.d/java.sh
chmod a+x /etc/profile.d/java.sh

source /etc/profile.d/java.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;instalação-do-bazel-0-3:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Instalação do Bazel 0.3&lt;/h3&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/build_deps/bazel-0.3.1-installer-linux-x86_64.sh --prefix=/opt/bazel-0.3.1

echo &#39;export PATH=$PATH:/opt/bazel-0.3.1/bin&#39; &amp;gt; /etc/profile.d/bazel.sh
chmod a+x /etc/profile.d/bazel.sh

source /etc/profile.d/bazel.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;construção-do-tensorflow-0-10:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Construção do TensorFlow 0.10&lt;/h3&gt;

&lt;p&gt;Considerações:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Configuração da GPU&lt;/p&gt;

&lt;p&gt;É necessário definir qual &amp;ldquo;Compute Capability&amp;rdquo; o binário do TensorFlow vai suportar.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-gpus&#34;&gt;https://developer.nvidia.com/cuda-gpus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Por exemplo:&lt;/p&gt;

&lt;p&gt;A GeForce GT 740M tem Compute Capability 3.0&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export TF_CUDA_COMPUTE_CAPABILITIES=3.0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Uso de Memória&lt;/p&gt;

&lt;p&gt;O build executa várias tarefas em paralelo e o consumo de memória pode aumentar rapidamente.&lt;/p&gt;

&lt;p&gt;Para limitar o número de execuções paralelas é usada a opção &lt;code&gt;-j 4&lt;/code&gt; no build.&lt;/p&gt;

&lt;p&gt;Em um notebook com 8 cores (HT), 8G de memória é insuficiente.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(comandos a serem executados dentro do container)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;useradd -m tensorflow
passwd -d tensorflow

su - tensorflow

git clone https://github.com/tensorflow/tensorflow.git -b r0.10 ~/tensorflow-0.10

cd ~/tensorflow-0.10

export PYTHON_BIN_PATH=/usr/bin/python
export TF_NEED_GCP=0
export TF_NEED_CUDA=1
export GCC_HOST_COMPILER_PATH=/usr/bin/gcc
export TF_CUDA_VERSION=8.0
export CUDA_TOOLKIT_PATH=/usr/local/cuda-8.0
export TF_CUDNN_VERSION=5
export CUDNN_INSTALL_PATH=/usr/local/cuda-8.0
export TF_CUDA_COMPUTE_CAPABILITIES=3.0
./configure

bazel build -j 4 -c opt --config=cuda \
    //tensorflow/tools/pip_package:build_pip_package

bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOME

mv ~/tensorflow-0.10.0-py2-none-{any,linux_x86_64}.whl

# saindo su
exit

# saindo do container
exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Para baixar o pacote (fora do container):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker cp \
    tensorflow_build:/home/tensorflow/tensorflow-0.10.0-py2-none-linux_x86_64.whl \
    .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusão:291e0c1fa75cdcafa45ea1a9fc30a281&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;O procedimento de build do TensorFlow não é complicado, mas pequenas variações podem atingir alguns bugs do build (&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/3985&#34;&gt;exemplo&lt;/a&gt;). Com um script bem definido, fica fácil criar o pacote do TensorFlow.&lt;/p&gt;

&lt;p&gt;Com esse pacote, é possível usar o TensorFlow nas GPUs mais recentes da Nvidia.&lt;/p&gt;

&lt;p&gt;No próximo artigo será um tutorial de como configurar um ambiente de desenvolvimento com Jupyter.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Otimização dos parâmetros do Spark ALS (Collaborative Filtering) usando MOE</title>
      <link>http://cirocavani.github.io/post/otimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe/</link>
      <pubDate>Thu, 24 Sep 2015 19:44:08 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/otimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe/</guid>
      <description>&lt;p&gt;Esse tutorial é sobre otimização de parâmetros em modelos de machine learning. Para esse tutorial, a ferramenta utilizada é o MOE, Metric Optimization Engine, desenvolvido pelo Yelp que implementa o algoritmo de busca usando Gaussian Process. O algoritmo escolhido para ter os parâmetros otimizados é o Collaborative Filtering baseado na fatoração da matriz de preferências. De forma genérica, esse é um processo que pode ser facilmente adaptado para outros algoritmos e permite sistematizar a árdua tarefa de escolher os melhores parâmetros para um modelo.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://yelp.github.io/MOE/&#34;&gt;http://yelp.github.io/MOE/&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;MOE (Metric Optimization Engine) is an efficient way to optimize a system’s parameters, when evaluating parameters is time-consuming or expensive.&lt;/p&gt;

&lt;p&gt;How does MOE work?&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Build a Gaussian Process (GP) with the historical data&lt;/li&gt;
&lt;li&gt;Optimize the hyperparameters of the Gaussian Process&lt;/li&gt;
&lt;li&gt;Find the point(s) of highest Expected Improvement (EI)&lt;/li&gt;
&lt;li&gt;Return the point(s) to sample, then repeat&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Primeiramente, é feita a instalação do MOE. Nesse processo, é necessário configurar o ambiente para compilar as dependências do projeto e o código que é composto por Python e C++. No final desse procedimento, o serviço do MOE estará disponível como um servidor REST e a API Python que pode ser usada para definir o procedimento de otimização.&lt;/p&gt;

&lt;p&gt;O procedimento de instalação em detalhes é descrito aqui:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://yelp.github.io/MOE/install.html#install-from-source&#34;&gt;http://yelp.github.io/MOE/install.html#install-from-source&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;
mkdir grandesdados-opt
cd grandesdados-opt

virtualenv --no-site-packages --python=python2.7 moe-env

&amp;gt; Running virtualenv with interpreter /usr/bin/python2.7
&amp;gt; New python executable in moe-env/bin/python2.7
&amp;gt; Also creating executable in moe-env/bin/python
&amp;gt; Installing setuptools, pip, wheel...done.

source moe-env/bin/activate

git clone https://github.com/Yelp/MOE.git
cd MOE

pip install -r requirements.txt

&amp;gt; (...)
&amp;gt; Successfully installed (...)

python setup.py install

&amp;gt; (...)

pserve --reload development.ini

&amp;gt; (...)
&amp;gt; Starting server in PID 23232.
&amp;gt; serving on 0.0.0.0:6543 view at http://127.0.0.1:6543

# (nesse momento, esse terminal fica &#39;preso&#39; mostrando o log do servidor do MOE)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O próximo passo é instalar o algoritmo que tem parâmetros que precisam ser otimizados.&lt;/p&gt;

&lt;p&gt;Nesse tutorial, será usado o algoritmo de Collaborative Filtering baseado na fatoração da matriz de preferências que gera um vetor para cada usuário e item da matriz original. Nesse algoritmo, os parâmetros são a dimensão do vetor a ser gerado (fatores latentes), o número de iterações para fatoração da matriz e o parâmetro de regularização usado na fatoração.&lt;/p&gt;

&lt;p&gt;O DataSet usado é um sample MovieLens que já vem na distribuição do Spark. São 1501 ratings, 30 usuários e 100 filmes.&lt;/p&gt;

&lt;p&gt;O código pode ser análisado aqui:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/apache/spark/blob/v1.5.0/examples/src/main/scala/org/apache/spark/examples/ml/MovieLensALS.scala&#34;&gt;https://github.com/apache/spark/blob/v1.5.0/examples/src/main/scala/org/apache/spark/examples/ml/MovieLensALS.scala&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(procedimento na mesma pasta anterior &lt;code&gt;grandesdados-opt&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O http://ftp.unicamp.br/pub/apache/spark/spark-1.5.0/spark-1.5.0-bin-hadoop2.6.tgz
tar zxf spark-1.5.0-bin-hadoop2.6.tgz
cd spark-1.5.0-bin-hadoop2.6/

cp conf/log4j.properties{.template,}
sed -i s/log4j\.rootCategory\=INFO/log4j\.rootCategory\=ERROR/1 conf/log4j.properties

echo &amp;quot;spark.ui.showConsoleProgress=false&amp;quot; &amp;gt; conf/spark-defaults.conf

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Executando o exemplo do MovieLens (a saída são os parâmetros):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;
./bin/run-example ml.MovieLensALS

&amp;gt; Error: Missing option --ratings
&amp;gt; Error: Missing option --movies
&amp;gt; MovieLensALS: an example app for ALS on MovieLens data.
&amp;gt; Usage: MovieLensALS [options]
&amp;gt;
&amp;gt;   --ratings &amp;lt;value&amp;gt;
&amp;gt;         path to a MovieLens dataset of ratings
&amp;gt;   --movies &amp;lt;value&amp;gt;
&amp;gt;         path to a MovieLens dataset of movies
&amp;gt;   --rank &amp;lt;value&amp;gt;
&amp;gt;         rank, default: 10
&amp;gt;   --maxIter &amp;lt;value&amp;gt;
&amp;gt;         max number of iterations, default: 10
&amp;gt;   --regParam &amp;lt;value&amp;gt;
&amp;gt;         regularization parameter, default: 0.1
&amp;gt;   --numBlocks &amp;lt;value&amp;gt;
&amp;gt;         number of blocks, default: 10
&amp;gt;
&amp;gt; Example command line to run this app:
&amp;gt;
&amp;gt;  bin/spark-submit --class org.apache.spark.examples.ml.MovieLensALS \
&amp;gt;   examples/target/scala-*/spark-examples-*.jar \
&amp;gt;   --rank 10 --maxIter 15 --regParam 0.1 \
&amp;gt;   --movies data/mllib/als/sample_movielens_movies.txt \
&amp;gt;   --ratings data/mllib/als/sample_movielens_ratings.txt

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Fazendo uma execução:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;
time ./bin/run-example ml.MovieLensALS \
--rank 10 --maxIter 15 --regParam 0.1 \
--movies data/mllib/als/sample_movielens_movies.txt \
--ratings data/mllib/als/sample_movielens_ratings.txt

&amp;gt; Got 1501 ratings from 30 users on 100 movies.                                   
&amp;gt; Training: 1169, test: 332.
&amp;gt; Test RMSE = 0.9815785141168548.                                                 
&amp;gt; Found 0 false positives                                                         
&amp;gt;
&amp;gt; real	0m22.441s
&amp;gt; user	0m56.320s
&amp;gt; sys	0m1.847s

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para fazer a otimização, o MOE requer que o problema seja modelado como uma função do vetor de parâmetros para um valor escalar. O objetivo da ferramenta é minimizar essa função.&lt;/p&gt;

&lt;p&gt;Para o problema do ALS, por simplicidade, vamos aproveitar que o exemplo já calcula o RMSE e usar a função que mapeia o vetor do Número de Fatores Latentes, Número de Iterações e Regularização para o RMSE. Faz sentido o objetivo ser minimizar o RMSE.&lt;/p&gt;

&lt;p&gt;Na pasta &lt;code&gt;grandesdados-opt&lt;/code&gt;, crie o arquivo &lt;code&gt;func.sh&lt;/code&gt; que mapeia a função desejada:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;#!/bin/bash

cd spark-1.5.0-bin-hadoop2.6/

./bin/run-example ml.MovieLensALS \
--rank $1 --maxIter $2 --regParam $3 \
--movies data/mllib/als/sample_movielens_movies.txt \
--ratings data/mllib/als/sample_movielens_ratings.txt 2&amp;gt;&amp;amp;1 \
| sed -n &#39;s/\(Test RMSE =\) \([0-9]*\.[0-9]*\)\./\2/p&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dessa forma, teremos:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;chmod +x func.sh

./func.sh 10 15 0.1

&amp;gt; 0.9815785141168546
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora podemos definir o procedimento de otimização como um experimento do MOE.&lt;/p&gt;

&lt;p&gt;O experimento é criado com o domínio dos parâmetros que estamos querendo otimizar. Dado que estamos trabalhando com um DataSet limitado, podemos restringir os valores.&lt;/p&gt;

&lt;p&gt;Nesse exemplo, estamos usando:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Número de Fatores Latentes: entre 5 e 50&lt;/li&gt;
&lt;li&gt;Número de Iterações da Fatoração: entre 5 e 20&lt;/li&gt;
&lt;li&gt;Regularização da Fatoração: entre 0.001 e 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Vamos assumir como primeiro ponto &amp;lsquo;ótimo&amp;rsquo; o que vem documentado no exemplo, ou seja, 10, 15 e 0,1.&lt;/p&gt;

&lt;p&gt;A busca por uma solução muito boa pode envolver muitas iterações do processo de otimização, nesse exemplo vamos usar 20, mas poderia ser 100 ou 400 para uma busca mais completa.&lt;/p&gt;

&lt;p&gt;Na pasta &lt;code&gt;grandesdados-opt&lt;/code&gt;, crie o arquivo &lt;code&gt;opt.py&lt;/code&gt; que define o procedimento de otimização:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import subprocess

from moe.easy_interface.experiment import Experiment
from moe.easy_interface.simple_endpoint import gp_next_points
from moe.optimal_learning.python.data_containers import SamplePoint

def function_to_minimize(x):
    f = &amp;quot;./func.sh {0:} {1:} {2:}&amp;quot;.format(int(x[0]), int(x[1]), x[2])
    print f
    y = subprocess.Popen(f, shell=True, stdout=subprocess.PIPE).stdout.read().strip()
    if y: print y
    return float(y)

if __name__ == &#39;__main__&#39;:
    exp = Experiment([[5, 50], [5, 20], [0.001, 1]])

    xmin = []
    ymin = 0.0

    for i in range(20):
        print &amp;quot;Sample {0:}&amp;quot;.format(i)
        try:
            x = [10.0, 15.0, 0.1] if i == 0 else gp_next_points(exp)[0]
            y = function_to_minimize(x)
            exp.historical_data.append_sample_points([
                SamplePoint(x, y, 0.05),
            ])
            if not xmin or y &amp;lt; ymin:
                xmin, ymin = x, y
        except ValueError:
            print &amp;quot;error&amp;quot;
        print

    print str(xmin)
    print str(ymin)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Por fim, o resultado:
&lt;br/&gt;(necessário estar dentro do virtualenv onde o MOE foi instalado)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python2 opt.py

&amp;gt; Sample 0
&amp;gt; ./func.sh 10 15 0.1
&amp;gt; 0.9815785141168545
&amp;gt; (...)
&amp;gt; Sample 19
&amp;gt; ./func.sh 16 19 0.41989952735
&amp;gt; error
&amp;gt;
&amp;gt; [46.6604641336, 19.9410400182, 0.0409527639665]
&amp;gt; 0.977384860516

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Como podemos ver, os parâmetros 46 para Número de Fatores Latentes, 19 para Iterações da Fatoração e 0,041 para Regularização resultaram em um erro menor nesse dataset de exemplo.&lt;/p&gt;

&lt;p&gt;Para mais informações sobre otimização usando o MOE, consulte a documentação.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Configuração do Hadoop, HBase e Kafka na Máquina Local com Docker</title>
      <link>http://cirocavani.github.io/post/configuracao-do-hadoop-hbase-e-kafka-na-maquina-local-com-docker/</link>
      <pubDate>Wed, 16 Sep 2015 23:26:07 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/configuracao-do-hadoop-hbase-e-kafka-na-maquina-local-com-docker/</guid>
      <description>

&lt;p&gt;Esse tutorial é sobre a criação de uma imagem do Docker com a configuração local do Hadoop, HBase e Kafka. Nesse procedimento, o Hadoop é configurado no modo pseudo-distribuído com cada serviço rodando em uma instância própria da JVM, mas todas na mesma máquina. O HBase e o Kafka também rodam em modo &amp;lsquo;distribuído&amp;rsquo; compartilhando uma instância separada do ZooKeeper. Esse procedimento é muito útil para testar funcionalidades desses serviços e aprendizado, mas não é uma solução completa para uso em produção.&lt;/p&gt;

&lt;h2 id=&#34;pré-requisito:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;Pré-requisito&lt;/h2&gt;

&lt;p&gt;Nesse procedimento, é necessário que o Docker esteja instalado e funcionando; também é necessário acesso à Internet.&lt;/p&gt;

&lt;p&gt;Originalmente, esse procedimento foi testado no ArchLinux atualizado até final de Agosto/2015.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.archlinux.org/index.php/Docker&#34;&gt;https://wiki.archlinux.org/index.php/Docker&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker version

&amp;gt; Client:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&amp;gt;
&amp;gt; Server:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuração:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;Configuração&lt;/h2&gt;

&lt;p&gt;Hadoop, ZooKeeper, HBase e Kafka.&lt;/p&gt;

&lt;h3 id=&#34;container:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;Container&lt;/h3&gt;

&lt;p&gt;Começamos com a criação de um conainer do Docker com a imagem do CentOS6.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Importante: para os endereços com &lt;code&gt;grandesdados-hadoop&lt;/code&gt; funcionarem fora do container, direto na máquina host, é necessário colocar no &lt;code&gt;/etc/hosts&lt;/code&gt; da máquina host o endereço IP do container do Docker para esse nome.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ao executar o comando &lt;code&gt;run&lt;/code&gt;, o Docker automaticamente fará o download da imagem e a shell será inicializada dentro de um novo container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker run -i -t --name=grandesdados-hadoop --hostname=grandesdados-hadoop centos:6 /bin/bash

&amp;gt; Unable to find image &#39;centos:6&#39; locally
&amp;gt; 6: Pulling from library/centos
&amp;gt;
&amp;gt; f1b10cd84249: Pull complete
&amp;gt; fb9cc58bde0c: Pull complete
&amp;gt; a005304e4e74: Already exists
&amp;gt; library/centos:6: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.
&amp;gt;
&amp;gt; Digest: sha256:25d94c55b37cb7a33ad706d5f440e36376fec20f59e57d16fe02c64698b531c1
&amp;gt; Status: Downloaded newer image for centos:6
&amp;gt; [root@grandesdados-hadoop /]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Já dentro do container criamos um usuário e local que serão usados para a instalação e execução dos processos.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;adduser -m -d /hadoop hadoop
cd hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A versão usada nesse procedimento é o Java 8, atual versão estável da Oracle.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -k -L -H &amp;quot;Cookie: oraclelicense=accept-securebackup-cookie&amp;quot; -O http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm
rpm -i jdk-8u60-linux-x64.rpm

echo &#39;export JAVA_HOME=&amp;quot;/usr/java/jdk1.8.0_60&amp;quot;&#39; &amp;gt; /etc/profile.d/java.sh
source /etc/profile.d/java.sh

echo $JAVA_HOME

&amp;gt; /usr/java/jdk1.8.0_60

java -version

&amp;gt; java version &amp;quot;1.8.0_60&amp;quot;
&amp;gt; Java(TM) SE Runtime Environment (build 1.8.0_60-b27)
&amp;gt; Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para completar o ambiente de execução, instalamos os serviços e bibliotecas necessárias.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yum install -y tar openssh-clients openssh-server rsync gzip zlib openssl fuse bzip2 snappy

&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(configuração do SSH para acesso sem senha)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;service sshd start
chkconfig sshd on

su - hadoop

ssh-keygen -C hadoop -P &#39;&#39; -f ~/.ssh/id_rsa
cp ~/.ssh/{id_rsa.pub,authorized_keys}

ssh-keyscan grandesdados-hadoop &amp;gt;&amp;gt;  ~/.ssh/known_hosts
ssh-keyscan localhost &amp;gt;&amp;gt; ~/.ssh/known_hosts
ssh-keyscan 127.0.0.1 &amp;gt;&amp;gt; ~/.ssh/known_hosts
ssh-keyscan 0.0.0.0 &amp;gt;&amp;gt; ~/.ssh/known_hosts

ssh grandesdados-hadoop

&amp;gt; Warning: Permanently added the RSA host key for IP address &#39;172.17.0.12&#39; to the list of known hosts.
&amp;gt; (nova shell, sem login nem confirmação)

# (sair do shell do ssh)
exit
# (sair do shell do su)
exit

whoami

&amp;gt; root
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;hadoop:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;Hadoop&lt;/h3&gt;

&lt;p&gt;Procedimento para configuração local do Hadoop em modo pseudo-distribuído com uma JVM por serviço.&lt;/p&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/SingleCluster.html&#34;&gt;documentação do Hadoop&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Serviços:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HDFS: NameNode, SecondaryNameNode, DataNode&lt;/li&gt;
&lt;li&gt;YARN: ResouceManager, NodeManager&lt;/li&gt;
&lt;li&gt;MR: HistoryServer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Instalação&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;O pacote usado nesse procedimento é o Hadoop 2.7.1 para CentOS6 descrito outro &lt;a href=&#34;http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/&#34;&gt;artigo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Primeiramente, colocamos o pacote dentro do container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# (shell fora do container)
sudo docker cp hadoop-2.7.1.tar.gz grandesdados-hadoop:/hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;De volta ao container como usuário root.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;tar zxf hadoop-2.7.1.tar.gz -C /opt
chown hadoop:hadoop -R /opt/hadoop-2.7.1

echo &#39;export PATH=$PATH:/opt/hadoop-2.7.1/bin:/opt/hadoop-2.7.1/sbin&#39; &amp;gt; /etc/profile.d/hadoop.sh
source /etc/profile.d/hadoop.sh

hadoop version

&amp;gt; Hadoop 2.7.1
&amp;gt; Subversion Unknown -r Unknown
&amp;gt; Compiled by hadoop on 2015-09-01T00:30Z
&amp;gt; Compiled with protoc 2.5.0
&amp;gt; From source with checksum fc0a1a23fc1868e4d5ee7fa2b28a58a
&amp;gt; This command was run using /opt/hadoop-2.7.1/share/hadoop/common/hadoop-common-2.7.1.jar

mkdir -p /data/hadoop
chown hadoop:hadoop /data/hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Configuração&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para a configuração, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/core-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/data/hadoop&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://grandesdados-hadoop&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/hdfs-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.blocksize&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;8M&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/yarn-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hadoop-2.7.1/etc/hadoop/mapred-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.jobtracker.staging.root.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/user&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setup Inicial (antes da primeira inicialização).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;hdfs namenode -format

&amp;gt; 15/09/16 02:12:03 INFO namenode.NameNode: STARTUP_MSG:
&amp;gt; /************************************************************
&amp;gt; STARTUP_MSG: Starting NameNode
&amp;gt; STARTUP_MSG:   host = grandesdados-hadoop/172.17.0.12
&amp;gt; STARTUP_MSG:   args = [-format]
&amp;gt; STARTUP_MSG:   version = 2.7.1
&amp;gt; (...)
&amp;gt; INFO namenode.NameNode: createNameNode [-format]
&amp;gt; Formatting using clusterid: CID-5daa32a0-3ab6-405e-bfd2-05c0a6e1e7e6
&amp;gt; (...)
&amp;gt; INFO common.Storage: Storage directory /data/hadoop/dfs/name has been successfully formatted.
&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;HDFS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(como usuário hadoop &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;start-dfs.sh

&amp;gt; Starting namenodes on [grandesdados-hadoop]
&amp;gt; grandesdados-hadoop: starting namenode, logging to /opt/hadoop-2.7.1/logs/hadoop-hadoop-namenode-grandesdados-hadoop.out
&amp;gt; localhost: starting datanode, logging to /opt/hadoop-2.7.1/logs/hadoop-hadoop-datanode-grandesdados-hadoop.out
&amp;gt; Starting secondary namenodes [0.0.0.0]
&amp;gt; 0.0.0.0: starting secondarynamenode, logging to /opt/hadoop-2.7.1/logs/hadoop-hadoop-secondarynamenode-grandesdados-hadoop.out

# criação do diretório do usuário hadoop
hdfs dfs -mkdir -p /user/hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do Name Node:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:50070/&#34;&gt;http://grandesdados-hadoop:50070/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Data Node (vazia):&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:50075/&#34;&gt;http://grandesdados-hadoop:50075/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Secondary Name Node:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:50090/&#34;&gt;http://grandesdados-hadoop:50090/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;stop-dfs.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;YARN&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(como usuário hadoop &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;start-yarn.sh

&amp;gt; starting yarn daemons
&amp;gt; starting resourcemanager, logging to /opt/hadoop-2.7.1/logs/yarn-hadoop-resourcemanager-grandesdados-hadoop.out
&amp;gt; localhost: starting nodemanager, logging to /opt/hadoop-2.7.1/logs/yarn-hadoop-nodemanager-grandesdados-hadoop.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do Resource Manager:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:8088/&#34;&gt;http://grandesdados-hadoop:8088/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Node Manager:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:8042/&#34;&gt;http://grandesdados-hadoop:8042/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;stop-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;History Server&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(como usuário hadoop &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mr-jobhistory-daemon.sh start historyserver

&amp;gt; starting historyserver, logging to /opt/hadoop-2.7.1/logs/mapred-hadoop-historyserver-grandesdados-hadoop.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do History Server:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:19888/&#34;&gt;http://grandesdados-hadoop:19888/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mr-jobhistory-daemon.sh stop historyserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processos:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x

&amp;gt;   PID TTY      STAT   TIME COMMAND
&amp;gt;  5162 ?        S      0:00 -bash
&amp;gt;  5327 ?        Sl     0:08 /usr/java/jdk1.8.0_60/bin/java -Dproc_namenode (...)
&amp;gt;  5423 ?        Sl     0:07 /usr/java/jdk1.8.0_60/bin/java -Dproc_datanode (...)
&amp;gt;  5612 ?        Sl     0:06 /usr/java/jdk1.8.0_60/bin/java -Dproc_secondarynamenode (...)
&amp;gt;  5772 ?        Sl     0:08 /usr/java/jdk1.8.0_60/bin/java -Dproc_resourcemanager (...)
&amp;gt;  5870 ?        Sl     0:07 /usr/java/jdk1.8.0_60/bin/java -Dproc_nodemanager (...)
&amp;gt;  6189 ?        Sl     0:08 /usr/java/jdk1.8.0_60/bin/java -Dproc_historyserver (...)
&amp;gt;  6273 ?        R+     0:00 ps x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Exemplos de MapReduce:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yarn jar /opt/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar

&amp;gt; An example program must be given as the first argument.
&amp;gt; Valid program names are:
&amp;gt;   aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
&amp;gt;   aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
&amp;gt;   bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
&amp;gt;   dbcount: An example job that count the pageview counts from a database.
&amp;gt;   distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
&amp;gt;   grep: A map/reduce program that counts the matches of a regex in the input.
&amp;gt;   join: A job that effects a join over sorted, equally partitioned datasets
&amp;gt;   multifilewc: A job that counts words from several files.
&amp;gt;   pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
&amp;gt;   pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
&amp;gt;   randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
&amp;gt;   randomwriter: A map/reduce program that writes 10GB of random data per node.
&amp;gt;   secondarysort: An example defining a secondary sort to the reduce.
&amp;gt;   sort: A map/reduce program that sorts the data written by the random writer.
&amp;gt;   sudoku: A sudoku solver.
&amp;gt;   teragen: Generate data for the terasort
&amp;gt;   terasort: Run the terasort
&amp;gt;   teravalidate: Checking results of terasort
&amp;gt;   wordcount: A map/reduce program that counts the words in the input files.
&amp;gt;   wordmean: A map/reduce program that counts the average length of the words in the input files.
&amp;gt;   wordmedian: A map/reduce program that counts the median length of the words in the input files.
&amp;gt;   wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Rodando o Cálculo do Pi com MapReduce:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yarn jar /opt/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 16 100000

&amp;gt; Number of Maps  = 16
&amp;gt; Samples per Map = 100000
&amp;gt; (...)
&amp;gt; INFO impl.YarnClientImpl: Submitted application application_1442439610364_0001
&amp;gt; INFO mapreduce.Job: The url to track the job: http://grandesdados-hadoop:8088/proxy/application_1442439610364_0001/
&amp;gt; INFO mapreduce.Job: Running job: job_1442439610364_0001
&amp;gt; (...)
&amp;gt; Job Finished in 48.333 seconds
&amp;gt; Estimated value of Pi is 3.14157500000000000000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;zookeeper:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;ZooKeeper&lt;/h3&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;https://zookeeper.apache.org/doc/r3.4.6/zookeeperStarted.html&#34;&gt;documentação do ZooKeeper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dentro do container como usuário root:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O http://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
tar zxf zookeeper-3.4.6.tar.gz -C /opt
chown hadoop:hadoop -R /opt/zookeeper-3.4.6

echo &#39;export PATH=$PATH:/opt/zookeeper-3.4.6/bin&#39; &amp;gt; /etc/profile.d/zookeeper.sh
source /etc/profile.d/zookeeper.sh

mkdir -p /data/zookeeper
chown hadoop:hadoop /data/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/zookeeper-3.4.6/conf/zoo.cfg&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;tickTime=6000
dataDir=/data/zookeeper
clientPort=2181
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicializando o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop
zkServer.sh start

&amp;gt; JMX enabled by default
&amp;gt; Using config: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
&amp;gt; Starting zookeeper ... STARTED
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;zkServer.sh stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x | grep zoo

&amp;gt; 8246 ?        Sl     0:00 /usr/java/jdk1.8.0_60/bin/java (...) org.apache.zookeeper.server.quorum.QuorumPeerMain (...)
&amp;gt; 8291 ?        S+     0:00 grep zoo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Telnet:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo &#39;ruok&#39; |  curl telnet://grandesdados-hadoop:2181

&amp;gt; imok
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cliente:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;zkCli.sh -server grandesdados-hadoop:2181

&amp;gt; Connecting to grandesdados-hadoop:2181
&amp;gt; ...
&amp;gt; [zk: grandesdados-hadoop:2181(CONNECTED) 0] ls /
&amp;gt; [zookeeper]
&amp;gt; [zk: grandesdados-hadoop:2181(CONNECTED) 1] help
&amp;gt; ZooKeeper -server host:port cmd args
&amp;gt; 	stat path [watch]
&amp;gt; 	set path data [version]
&amp;gt; 	ls path [watch]
&amp;gt; 	delquota [-n|-b] path
&amp;gt; 	ls2 path [watch]
&amp;gt; 	setAcl path acl
&amp;gt; 	setquota -n|-b val path
&amp;gt; 	history
&amp;gt; 	redo cmdno
&amp;gt; 	printwatches on|off
&amp;gt; 	delete path [version]
&amp;gt; 	sync path
&amp;gt; 	listquota path
&amp;gt; 	rmr path
&amp;gt; 	get path [watch]
&amp;gt; 	create [-s] [-e] path data acl
&amp;gt; 	addauth scheme auth
&amp;gt; 	quit
&amp;gt; 	getAcl path
&amp;gt; 	close
&amp;gt; 	connect host:port
&amp;gt; [zk: grandesdados-hadoop:2181(CONNECTED) 3] quit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;hbase:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;HBase&lt;/h3&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;http://hbase.apache.org/book.html#quickstart&#34;&gt;documentação do HBase&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dentro do container como usuário root:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O http://archive.apache.org/dist/hbase/1.1.2/hbase-1.1.2-bin.tar.gz
tar zxf hbase-1.1.2-bin.tar.gz -C /opt
chown hadoop:hadoop -R /opt/hbase-1.1.2

echo &#39;export PATH=$PATH:/opt/hbase-1.1.2/bin&#39; &amp;gt; /etc/profile.d/hbase.sh
source /etc/profile.d/hbase.sh

mkdir -p /data/hbase/tmp
chown hadoop:hadoop -R /data/hbase
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hbase-1.1.2/conf/hbase-site.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs:///hbase&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/data/hbase/tmp&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;grandesdados-hadoop&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/hbase-1.1.2/conf/hbase-env.sh&lt;/code&gt;:
&lt;br/&gt;(manter conteúdo original, só alterar os valores abaixo)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export HBASE_OPTS=&amp;quot;-XX:+UseConcMarkSweepGC -Djava.net.preferIPv4Stack=true&amp;quot;
export HBASE_MANAGES_ZK=false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicializando o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop
start-hbase.sh

&amp;gt; starting master, logging to /opt/hbase-1.1.2/bin/../logs/hbase-hadoop-master-grandesdados-hadoop.out
&amp;gt; Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0
&amp;gt; Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0
&amp;gt; starting regionserver, logging to /opt/hbase-1.1.2/bin/../logs/hbase-hadoop-1-regionserver-grandesdados-hadoop.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Interface Web do Master:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:16010/&#34;&gt;http://grandesdados-hadoop:16010/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interface Web do Region Server:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://grandesdados-hadoop:16301/&#34;&gt;http://grandesdados-hadoop:16301/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;stop-hbase.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x | grep hbase

&amp;gt; 8790 ?        S      0:00 bash /opt/hbase-1.1.2/bin/hbase-daemon.sh --config /opt/hbase-1.1.2/bin/../conf foreground_start master
&amp;gt; 8804 ?        Sl     0:14 /usr/java/jdk1.8.0_60/bin/java -Dproc_master (...)
&amp;gt; 8915 ?        S      0:00 bash /opt/hbase-1.1.2/bin/hbase-daemon.sh --config /opt/hbase-1.1.2/bin/../conf foreground_start regionserver -D hbase.regionserver.port=16201 -D hbase.regionserver.info.port=16301
&amp;gt; 8929 ?        Sl     0:14 /usr/java/jdk1.8.0_60/bin/java -Dproc_regionserver (...)
&amp;gt; 9329 ?        S+     0:00 grep hbase
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cliente:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;hbase shell

&amp;gt; HBase Shell; enter &#39;help&amp;lt;RETURN&amp;gt;&#39; for list of supported commands.
&amp;gt; Type &amp;quot;exit&amp;lt;RETURN&amp;gt;&amp;quot; to leave the HBase Shell
&amp;gt; Version 1.1.2, rcc2b70cf03e3378800661ec5cab11eb43fafe0fc, Wed Aug 26 20:11:27 PDT 2015
&amp;gt;
&amp;gt; hbase(main):001:0&amp;gt; status
&amp;gt; 1 servers, 0 dead, 2.0000 average load
&amp;gt;
&amp;gt; hbase(main):002:0&amp;gt; help
&amp;gt; HBase Shell, version 1.1.2, rcc2b70cf03e3378800661ec5cab11eb43fafe0fc, Wed Aug 26 20:11:27 PDT 2015
&amp;gt; Type &#39;help &amp;quot;COMMAND&amp;quot;&#39;, (e.g. &#39;help &amp;quot;get&amp;quot;&#39; -- the quotes are necessary) for help on a specific command.
&amp;gt; Commands are grouped. Type &#39;help &amp;quot;COMMAND_GROUP&amp;quot;&#39;, (e.g. &#39;help &amp;quot;general&amp;quot;&#39;) for help on a command group.
&amp;gt; (...)
&amp;gt; hbase(main):004:0&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kafka:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;Kafka&lt;/h3&gt;

&lt;p&gt;Esse procedimento é baseado na &lt;a href=&#34;http://kafka.apache.org/documentation.html#quickstart&#34;&gt;documentação do Kafka&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dentro do container como usuário root:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O http://archive.apache.org/dist/kafka/0.8.2.1/kafka_2.10-0.8.2.1.tgz
tar zxf kafka_2.10-0.8.2.1.tgz -C /opt
chown hadoop:hadoop -R /opt/kafka_2.10-0.8.2.1

echo &#39;export PATH=$PATH:/opt/kafka_2.10-0.8.2.1/bin&#39; &amp;gt; /etc/profile.d/kafka.sh
source /etc/profile.d/kafka.sh

mkdir -p /data/kafka
chown hadoop:hadoop /data/kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Editar &lt;code&gt;/opt/kafka_2.10-0.8.2.1/config/server.properties&lt;/code&gt;:
&lt;br/&gt;(manter conteúdo original, só alterar os valores abaixo)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;log.dirs=/data/kafka
zookeeper.connect=grandesdados-hadoop:2181
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicializando o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop
kafka-server-start.sh /opt/kafka_2.10-0.8.2.1/config/server.properties &amp;amp;&amp;gt; kafka.out &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para parar o serviço:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;kafka-server-stop.sh /opt/kafka_2.10-0.8.2.1/config/server.properties
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Teste&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(para os testes, deve ser usado o usuário hadoop: &lt;code&gt;su - hadoop&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;Processo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ps x | grep kafka

&amp;gt; 9818 ?        Sl     0:03 /usr/java/jdk1.8.0_60/bin/java (...) kafka.Kafka /opt/kafka_2.10-0.8.2.1/config/server.properties
&amp;gt; 9928 ?        S+     0:00 grep kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enviando e recebendo mensagens:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;kafka-topics.sh \
--create \
--zookeeper grandesdados-hadoop:2181 \
--replication-factor 1 \
--partitions 1 \
--topic test

&amp;gt; Created topic &amp;quot;test&amp;quot;.

echo &#39;Primeira mensagem de teste&#39; | kafka-console-producer.sh --broker-list grandesdados-hadoop:9092 --topic test

&amp;gt; (...)

kafka-console-consumer.sh --zookeeper grandesdados-hadoop:2181 --topic test --from-beginning

&amp;gt; Primeira mensagem de teste
&amp;gt; ^CConsumed 1 messages
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusão:7662b18c2fa1b345b82a7d885cf16b10&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;A revolução em BigData é um fenômeno da tecnologia desenvolvida ao longo dos últimos anos focada na manipulação de um grande volume de dados em máquinas de baixo custo. Essa é a tecnologia que torna possível combinar uma solução de dados escalável com processos para geração de resultados relevantes, tanto no desenvolvimento de produtos quanto na evolução do conhecimento. O importante é entender como essa tecnologia pode ser usada para agregar valor ao negócio e permitir imaginar soluções inovadoras.&lt;/p&gt;

&lt;p&gt;Esse artigo documenta o passo-a-passo de uma configuração local do Hadoop, ZooKeeper, HBase e Kafka. Esses são os serviços essenciais em uma plataforma de BigData que, juntamente com o Spark, possibilitam o desenvolvimento de soluções tanto para processamento batch quanto para tempo real.&lt;/p&gt;

&lt;p&gt;Em artigos futuros, entrarei usando essa solução para desenvolver e testar algumas aplicações de BigData usando Spark.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compilação do Spark 1.5 (com bugfix)</title>
      <link>http://cirocavani.github.io/post/compilacao-do-spark-15-com-bugfix/</link>
      <pubDate>Fri, 11 Sep 2015 08:10:00 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-spark-15-com-bugfix/</guid>
      <description>

&lt;p&gt;Aproveitando que foi feito o lançamento da versão 1.5.0 do Spark, esse tutorial é sobre a construção do pacote do Spark usando o branch atualizado. O branch foi criado para fazer a estabilização do código que deu origem ao primeiro release. Esse branch continua recebendo atualizações importantes que farão parte de releases bugfix no futuro. Com esse procedimento, é possível gerar o pacote com essas últimas atualizações (e até customizar com alterações próprias) antecipando correções que podem ajudar em produção. Importante entender que ao usar uma versão que não passou pelo release implica em riscos que devem ser mitigados com muitos testes.&lt;/p&gt;

&lt;p&gt;Mais informações sobre a construção do Spark podem ser obtidas na documentação &lt;a href=&#34;http://spark.apache.org/docs/latest/building-spark.html&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Mais informações sobre a última versão Spark 1.5.0 no &lt;a href=&#34;http://spark.apache.org/releases/spark-release-1-5-0.html&#34;&gt;Release Notes&lt;/a&gt; e no blog da Databricks &lt;a href=&#34;https://databricks.com/blog/2015/09/09/announcing-spark-1-5.html&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;pré-requisito:a471447a7b0c139f517b6888cdad9c6e&#34;&gt;Pré-requisito&lt;/h2&gt;

&lt;p&gt;O procedimento consiste em: provisionar o ambiente; fazer uma cópia do branch estável da última versão, e; gerar o pacote binário e os artefatos do Maven.&lt;/p&gt;

&lt;p&gt;As ferramentas necessárias para construção são git, Java 7 e Maven 3.3.&lt;/p&gt;

&lt;p&gt;Todo o procedimento é executado na linha de comando do terminal.&lt;/p&gt;

&lt;p&gt;(é assumido que o git já está instalado)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Java&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A versão usada nesse procedimento é o Java 7 para o qual a Oracle já terminou o ciclo de desenvolvimento das releases públicas (gratuitas). Contudo, essa é a versão que tem melhor suporte nas ferramentas que estaremos usando com Spark.&lt;/p&gt;

&lt;p&gt;(também tem suporte para o Java 8, mas o interesse é usar esse pacote no Hadoop 2.7 que ainda não suporta oficialmente essa versão)&lt;/p&gt;

&lt;p&gt;Segue o procedimento para Linux e MacOSX.&lt;/p&gt;

&lt;p&gt;(Linux)&lt;/p&gt;

&lt;p&gt;No Linux, para o Java, é usado o JDK da Oracle.&lt;/p&gt;

&lt;p&gt;(nesse procedimento, foi usado o ArchLinux atualizado até essa primeira semana de Setembro)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget --no-check-certificate --no-cookies --header &amp;quot;Cookie: oraclelicense=accept-securebackup-cookie&amp;quot; http://download.oracle.com/otn-pub/java/jdk/7u80-b15/jdk-7u80-linux-x64.tar.gz

tar zxf jdk-7u80-linux-x64.tar.gz

export JAVA_HOME=`pwd`/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH

java -version

&amp;gt; java version &amp;quot;1.7.0_80&amp;quot;
&amp;gt; Java(TM) SE Runtime Environment (build 1.7.0_80-b15)
&amp;gt; Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(OSX)&lt;/p&gt;

&lt;p&gt;No MacOSX, é necessário baixar o pacote no site da Oracle e fazer a instalação.&lt;/p&gt;

&lt;p&gt;Download do Java 7 &lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u80-oth-JPR&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;No terminal, a versão específica do Java pode ser configurada ajustando a variável de ambiente:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export JAVA_HOME=&amp;quot;$(/usr/libexec/java_home -v 1.7)&amp;quot;

java -version

&amp;gt; java version &amp;quot;1.7.0_80&amp;quot;
&amp;gt; Java(TM) SE Runtime Environment (build 1.7.0_80-b15)
&amp;gt; Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Maven&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A construção do Spark depende da versão 3.3 do Maven.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget http://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz

tar zxf apache-maven-3.3.3-bin.tar.gz

export PATH=`pwd`/apache-maven-3.3.3/bin

mvn -version

&amp;gt; Apache Maven 3.3.3 (7994120775791599e205a5524ec3e0dfe41d4a06; 2015-04-22T08:57:37-03:00)
&amp;gt; Maven home: /home/cavani/Software/apache-maven-3.3.3
&amp;gt; Java version: 1.7.0_80, vendor: Oracle Corporation
&amp;gt; Java home: /home/cavani/Software/jdk1.7.0_80/jre
&amp;gt; Default locale: en_US, platform encoding: UTF-8
&amp;gt; OS name: &amp;quot;linux&amp;quot;, version: &amp;quot;4.0.4-2-arch&amp;quot;, arch: &amp;quot;amd64&amp;quot;, family: &amp;quot;unix&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;compilação:a471447a7b0c139f517b6888cdad9c6e&#34;&gt;Compilação&lt;/h2&gt;

&lt;p&gt;Primeiramente é criado um clone local do repositório do Spark no qual é desenvolvido a versão 1.5 (estável).&lt;/p&gt;

&lt;p&gt;(use &lt;code&gt;--depth 1&lt;/code&gt; para baixar apenas os arquivos finais, sem o histórico de mudanças, diminui o download)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/apache/spark.git --branch branch-1.5 spark-1.5

&amp;gt; Cloning into &#39;spark-1.5&#39;...
&amp;gt; remote: Counting objects: 256928, done.
&amp;gt; remote: Total 256928 (delta 0), reused 0 (delta 0), pack-reused 256928
&amp;gt; Receiving objects: 100% (256928/256928), 121.38 MiB | 1.23 MiB/s, done.
&amp;gt; Resolving deltas: 100% (108225/108225), done.
&amp;gt; Checking connectivity... done.

cd spark-1.5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A partir desse branch serão criados todos os releases 1.5.x.&lt;/p&gt;

&lt;p&gt;Já foi feito o release da tag v1.5.0 e está aberto o desenvolvimento da versão 1.5.1 (ou seja, a versão corrente no branch é a 1.5.1-SNAPSHOT).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git log --oneline -30

&amp;gt; 89d351b Revert &amp;quot;[SPARK-6350] [MESOS] Fine-grained mode scheduler respects mesosExecutor.cores&amp;quot;
&amp;gt; (...)
&amp;gt; 2b270a1 Preparing development version 1.5.1-SNAPSHOT
&amp;gt; 908e37b Preparing Spark release v1.5.0-rc3
&amp;gt; 1c752b8 [SPARK-10341] [SQL] fix memory starving in unsafe SMJ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O versionamento será com base na versão do último release e a identificação dos bugfix será feita no nome do pacote, preservado a substituição transparente da versão oficial pela atualizada.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mvn help:evaluate -Dexpression=project.version | grep -v INFO | grep -v WARNING | grep -v Download

&amp;gt; 1.5.1-SNAPSHOT

mvn versions:set -DnewVersion=1.5.0 -DgenerateBackupPoms=false

&amp;gt; (...)
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO]
&amp;gt; [INFO] Spark Project Parent POM ........................... SUCCESS [  4.559 s]
&amp;gt; (...)
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Por fim, a construção do pacote.&lt;/p&gt;

&lt;p&gt;Nesse caso estaremos construindo um pacote com suporte ao YARN no Hadoop 2.7.1, suporte Hive com JDBC.&lt;/p&gt;

&lt;p&gt;Estamos colocando no nome do pacote o número do último commit.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export MAVEN_OPTS=&amp;quot;-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m&amp;quot;

./make-distribution.sh --name 89d351b --tgz --skip-java-test -Phadoop-2.6 -Pyarn -Phive -Phive-thriftserver -Dhadoop.version=2.7.1

&amp;gt; (...)
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO]
&amp;gt; [INFO] Spark Project Parent POM ........................... SUCCESS [  3.841 s]
&amp;gt; [INFO] Spark Project Launcher ............................. SUCCESS [ 12.819 s]
&amp;gt; [INFO] Spark Project Networking ........................... SUCCESS [ 10.980 s]
&amp;gt; [INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [  6.876 s]
&amp;gt; [INFO] Spark Project Unsafe ............................... SUCCESS [ 15.828 s]
&amp;gt; [INFO] Spark Project Core ................................. SUCCESS [03:19 min]
&amp;gt; [INFO] Spark Project Bagel ................................ SUCCESS [  7.048 s]
&amp;gt; [INFO] Spark Project GraphX ............................... SUCCESS [ 18.493 s]
&amp;gt; [INFO] Spark Project Streaming ............................ SUCCESS [ 41.120 s]
&amp;gt; [INFO] Spark Project Catalyst ............................. SUCCESS [01:01 min]
&amp;gt; [INFO] Spark Project SQL .................................. SUCCESS [01:22 min]
&amp;gt; [INFO] Spark Project ML Library ........................... SUCCESS [01:13 min]
&amp;gt; [INFO] Spark Project Tools ................................ SUCCESS [  2.460 s]
&amp;gt; [INFO] Spark Project Hive ................................. SUCCESS [ 58.477 s]
&amp;gt; [INFO] Spark Project REPL ................................. SUCCESS [ 11.646 s]
&amp;gt; [INFO] Spark Project YARN ................................. SUCCESS [ 14.443 s]
&amp;gt; [INFO] Spark Project Hive Thrift Server ................... SUCCESS [ 11.609 s]
&amp;gt; [INFO] Spark Project Assembly ............................. SUCCESS [02:02 min]
&amp;gt; [INFO] Spark Project External Twitter ..................... SUCCESS [  8.653 s]
&amp;gt; [INFO] Spark Project External Flume Sink .................. SUCCESS [  5.997 s]
&amp;gt; [INFO] Spark Project External Flume ....................... SUCCESS [ 12.408 s]
&amp;gt; [INFO] Spark Project External Flume Assembly .............. SUCCESS [  3.959 s]
&amp;gt; [INFO] Spark Project External MQTT ........................ SUCCESS [ 22.884 s]
&amp;gt; [INFO] Spark Project External MQTT Assembly ............... SUCCESS [  8.830 s]
&amp;gt; [INFO] Spark Project External ZeroMQ ...................... SUCCESS [  8.407 s]
&amp;gt; [INFO] Spark Project External Kafka ....................... SUCCESS [ 14.933 s]
&amp;gt; [INFO] Spark Project Examples ............................. SUCCESS [01:52 min]
&amp;gt; [INFO] Spark Project External Kafka Assembly .............. SUCCESS [  7.171 s]
&amp;gt; [INFO] Spark Project YARN Shuffle Service ................. SUCCESS [  7.010 s]
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Total time: 16:08 min
&amp;gt; [INFO] Finished at: 2015-09-11T06:44:55-03:00
&amp;gt; [INFO] Final Memory: 417M/1553M
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resultado:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spark-1.5.0-bin-89d351b.tgz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;(Artefatos do Maven)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;rm -rf ~/.m2/repository/org/apache/spark

mvn install -Phadoop-2.6 -Pyarn -Phive -Phive-thriftserver -Dhadoop.version=2.7.1 -DskipTests

&amp;gt; (...)
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO]
&amp;gt; [INFO] Spark Project Parent POM ........................... SUCCESS [  4.339 s]
&amp;gt; [INFO] Spark Project Launcher ............................. SUCCESS [ 14.078 s]
&amp;gt; [INFO] Spark Project Networking ........................... SUCCESS [  8.555 s]
&amp;gt; [INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [  3.540 s]
&amp;gt; [INFO] Spark Project Unsafe ............................... SUCCESS [  3.395 s]
&amp;gt; [INFO] Spark Project Core ................................. SUCCESS [01:22 min]
&amp;gt; [INFO] Spark Project Bagel ................................ SUCCESS [  7.293 s]
&amp;gt; [INFO] Spark Project GraphX ............................... SUCCESS [ 15.367 s]
&amp;gt; [INFO] Spark Project Streaming ............................ SUCCESS [ 26.005 s]
&amp;gt; [INFO] Spark Project Catalyst ............................. SUCCESS [ 49.232 s]
&amp;gt; [INFO] Spark Project SQL .................................. SUCCESS [ 48.866 s]
&amp;gt; [INFO] Spark Project ML Library ........................... SUCCESS [01:01 min]
&amp;gt; [INFO] Spark Project Tools ................................ SUCCESS [  8.979 s]
&amp;gt; [INFO] Spark Project Hive ................................. SUCCESS [ 29.601 s]
&amp;gt; [INFO] Spark Project REPL ................................. SUCCESS [ 19.661 s]
&amp;gt; [INFO] Spark Project YARN ................................. SUCCESS [ 16.976 s]
&amp;gt; [INFO] Spark Project Hive Thrift Server ................... SUCCESS [ 13.583 s]
&amp;gt; [INFO] Spark Project Assembly ............................. SUCCESS [02:01 min]
&amp;gt; [INFO] Spark Project External Twitter ..................... SUCCESS [  9.734 s]
&amp;gt; [INFO] Spark Project External Flume Sink .................. SUCCESS [ 10.291 s]
&amp;gt; [INFO] Spark Project External Flume ....................... SUCCESS [ 12.282 s]
&amp;gt; [INFO] Spark Project External Flume Assembly .............. SUCCESS [  4.252 s]
&amp;gt; [INFO] Spark Project External MQTT ........................ SUCCESS [ 21.910 s]
&amp;gt; [INFO] Spark Project External MQTT Assembly ............... SUCCESS [  8.383 s]
&amp;gt; [INFO] Spark Project External ZeroMQ ...................... SUCCESS [  7.677 s]
&amp;gt; [INFO] Spark Project External Kafka ....................... SUCCESS [ 13.317 s]
&amp;gt; [INFO] Spark Project Examples ............................. SUCCESS [01:45 min]
&amp;gt; [INFO] Spark Project External Kafka Assembly .............. SUCCESS [  6.813 s]
&amp;gt; [INFO] Spark Project YARN Shuffle Service ................. SUCCESS [  7.544 s]
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Total time: 12:24 min
&amp;gt; [INFO] Finished at: 2015-09-11T07:52:35-03:00
&amp;gt; [INFO] Final Memory: 102M/1349M
&amp;gt; [INFO] ------------------------------------------------------------------------

cd ~/.m2/repository
tar cf spark-1.5.0-m2-89d351b.tar org/apache/spark

cd -
mv ~/.m2/repository/spark-1.5.0-m2-89d351b.tar .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resultado:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spark-1.5.0-m2-89d351b.tar&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusão:a471447a7b0c139f517b6888cdad9c6e&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;O Spark é um framework que vem evoluindo rapidamente, com contribuições das mais diversas origem. Praticamente todos os grandes de BigData estão contribuindo com o Spark. Muitas vezes, surgem novas funcionalidades que podem agregar muito valor nas suas aplicações. Outras vezes, são bugs corrigidos que contribuem para a estabilidade de uma aplicação que já existe. Também tem o &amp;lsquo;prazer&amp;rsquo; de ser um &amp;lsquo;early adopter&amp;rsquo;. Seja qual for o motivo, esse procedimento mostra que o trabalho para ter um pacote do Spark é bem fácil e, por experiência, esse é um fator bastante relevante para ganhar tempo e gerar máximo valor.&lt;/p&gt;

&lt;p&gt;Nos próximos artigos, vou falar mais de como usar o Spark para desenvolver um aplicação que roda no Hadoop.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compilação do Hadoop para CentOS6 / RHEL6 usando Docker</title>
      <link>http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</link>
      <pubDate>Mon, 31 Aug 2015 22:45:23 -0300</pubDate>
      
      <guid>http://cirocavani.github.io/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</guid>
      <description>

&lt;p&gt;Esse tutorial é sobre a construção do pacote do Hadoop 2.7.1 para o CentOS6 / RHEL6 usando Docker. Esse procedimento é necessário para gerar as bibliotecas nativas compatíveis. O principal objetivo que motivou esse trabalho foi configurar o FairScheduler do YARN usando CGroups rodando no Red Hat Enterprise Linux 6 (RHEL6). O pacote Hadoop distribuído pela Apache tem executável binário que não é compatível com a Glibc que faz parte do CentOS6/RHEL6.&lt;/p&gt;

&lt;p&gt;O RHEL6 é o sistema operacional homologado para as máquinas do cluster que usamos na Globo.com e foi necessário criar uma distribuição própria do Hadoop para que pudéssemos fazer uso do &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/FairScheduler.html&#34;&gt;FairScheduler&lt;/a&gt; juntamente com o &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html&#34;&gt;CGroups&lt;/a&gt; para limitar o uso de processamento entre as aplicações rodando nos mesmos NodeManagers.&lt;/p&gt;

&lt;p&gt;Esse trabalho de configuração do Hadoop para uso compartilhado será assunto de outro artigo.&lt;/p&gt;

&lt;p&gt;Nesse artigo, o foco é um passo a passo de como usar o Docker para gerar um pacote do Hadoop adaptado para o Red Hat Enterprise Linux 6 (RHEL6) usando CentOS6.&lt;/p&gt;

&lt;h2 id=&#34;pré-requisito:ac8d87b01c866329a85ac2f7311bc677&#34;&gt;Pré-requisito&lt;/h2&gt;

&lt;p&gt;Nesse procedimento, é necessário que o Docker esteja instalado e funcionando; também é necessário acesso à Internet.&lt;/p&gt;

&lt;p&gt;Originalmente, esse procedimento foi testado no ArchLinux atualizado até final de Agosto/2015.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.archlinux.org/index.php/Docker&#34;&gt;https://wiki.archlinux.org/index.php/Docker&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker version

&amp;gt; Client:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&amp;gt;
&amp;gt; Server:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;compilação:ac8d87b01c866329a85ac2f7311bc677&#34;&gt;Compilação&lt;/h2&gt;

&lt;p&gt;Documento com instruções de build do Hadoop &lt;a href=&#34;https://github.com/apache/hadoop/blob/release-2.7.1/BUILDING.txt&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;O resultado desse procedimento é um pacote do Hadoop com os executáveis e bibliotecas nativas compilados para o CentOS6 que rodam no RHEL6.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Começamos com a criação de um conainer do Docker com a imagem do CentOS6.&lt;/p&gt;

&lt;p&gt;Ao executar o comando &lt;code&gt;run&lt;/code&gt;, o Docker automaticamente fará o download da imagem e a shell será inicializada dentro de um novo container.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker run -i -t centos:6 /bin/bash

&amp;gt; Unable to find image &#39;centos:6&#39; locally
&amp;gt; 6: Pulling from library/centos
&amp;gt;
&amp;gt; f1b10cd84249: Pull complete
&amp;gt; fb9cc58bde0c: Pull complete
&amp;gt; a005304e4e74: Already exists
&amp;gt; library/centos:6: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.
&amp;gt;
&amp;gt; Digest: sha256:25d94c55b37cb7a33ad706d5f440e36376fec20f59e57d16fe02c64698b531c1
&amp;gt; Status: Downloaded newer image for centos:6
&amp;gt; [root@3cc2bc5e593b /]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Já dentro do container criamos um usuário e local que serão usados na compilação e geração do pacote.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;adduser -m -d /hadoop hadoop
cd hadoop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para a compilação das bibliotecas nativas é necessária a instalação do compilador C e mais alguns pacotes de desenvolvimento (cabeçalhos das bibliotecas usadas pelo Hadoop).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;yum install -y tar gzip gcc-c++ cmake zlib zlib-devel openssl openssl-devel fuse fuse-devel bzip2 bzip2-devel snappy snappy-devel

&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O Hadoop ainda depende de duas outras bibliotecas que precisam ser instaladas manualmente no CentOS: Google ProtoBuf 2.5 (RPC), Jansson (JSON).&lt;/p&gt;

&lt;p&gt;Para instalar o ProtoBuf, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -L -O https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
tar zxf protobuf-2.5.0.tar.gz
cd protobuf-2.5.0
./configure --prefix=/usr --libdir=/usr/lib64
make
make check
make install

cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para instalar o Jansson, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -O http://www.digip.org/jansson/releases/jansson-2.7.tar.gz
tar zxf jansson-2.7.tar.gz
cd jansson-2.7
./configure --prefix=/usr --libdir=/usr/lib64
make
make install

cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para completar o ambiente de compilação, precisamos do JDK e do Maven.&lt;/p&gt;

&lt;p&gt;No caso do JDK, usaremos o pacote RPM já disponibilizado pela Oracle.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -k -L -H &amp;quot;Cookie: oraclelicense=accept-securebackup-cookie&amp;quot; -O http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm
rpm -i jdk-8u60-linux-x64.rpm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No caso do Maven, usaremos o pacote binário de distribuição da Apache.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -O http://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz
tar zxf apache-maven-3.3.3-bin.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O ambiente  de compilação está completo.&lt;/p&gt;

&lt;p&gt;Agora estamos pronto para a compilação do Hadoop. Nesse caso, estaremos gerando o pacote de distribuição somente com o binário Java e as bibliotecas nativas.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;su - hadoop

export PATH=$PATH:/hadoop/apache-maven-3.3.3/bin

curl -O http://archive.apache.org/dist/hadoop/common/hadoop-2.7.1/hadoop-2.7.1-src.tar.gz
tar zxf hadoop-2.7.1-src.tar.gz
cd hadoop-2.7.1-src

mvn clean package -Pdist,native -DskipTests -Drequire.snappy -Drequire.openssl -Dtar

&amp;gt; (...)
&amp;gt; main:
&amp;gt;      [exec] $ tar cf hadoop-2.7.1.tar hadoop-2.7.1
&amp;gt;      [exec] $ gzip -f hadoop-2.7.1.tar
&amp;gt;      [exec]
&amp;gt;      [exec] Hadoop dist tar available at: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz
&amp;gt;      [exec]
&amp;gt; [INFO] Executed tasks
&amp;gt; [INFO]
&amp;gt; [INFO] --- maven-javadoc-plugin:2.8.1:jar (module-javadocs) @ hadoop-dist ---
&amp;gt; [INFO] Building jar: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-dist-2.7.1-javadoc.jar
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO]
&amp;gt; [INFO] Apache Hadoop Main ................................. SUCCESS [01:56 min]
&amp;gt; [INFO] Apache Hadoop Project POM .......................... SUCCESS [ 42.134 s]
&amp;gt; [INFO] Apache Hadoop Annotations .......................... SUCCESS [ 37.761 s]
&amp;gt; [INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.125 s]
&amp;gt; [INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [ 23.183 s]
&amp;gt; [INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 25.962 s]
&amp;gt; [INFO] Apache Hadoop MiniKDC .............................. SUCCESS [03:23 min]
&amp;gt; [INFO] Apache Hadoop Auth ................................. SUCCESS [02:11 min]
&amp;gt; [INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 10.145 s]
&amp;gt; [INFO] Apache Hadoop Common ............................... SUCCESS [03:29 min]
&amp;gt; [INFO] Apache Hadoop NFS .................................. SUCCESS [  4.724 s]
&amp;gt; [INFO] Apache Hadoop KMS .................................. SUCCESS [02:35 min]
&amp;gt; [INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.024 s]
&amp;gt; [INFO] Apache Hadoop HDFS ................................. SUCCESS [02:15 min]
&amp;gt; [INFO] Apache Hadoop HttpFS ............................... SUCCESS [02:13 min]
&amp;gt; [INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [ 38.598 s]
&amp;gt; [INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  3.213 s]
&amp;gt; [INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.032 s]
&amp;gt; [INFO] hadoop-yarn ........................................ SUCCESS [  0.030 s]
&amp;gt; [INFO] hadoop-yarn-api .................................... SUCCESS [ 29.193 s]
&amp;gt; [INFO] hadoop-yarn-common ................................. SUCCESS [02:02 min]
&amp;gt; [INFO] hadoop-yarn-server ................................. SUCCESS [  0.040 s]
&amp;gt; [INFO] hadoop-yarn-server-common .......................... SUCCESS [  8.499 s]
&amp;gt; [INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [ 12.283 s]
&amp;gt; [INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [  2.359 s]
&amp;gt; [INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [  5.298 s]
&amp;gt; [INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 15.095 s]
&amp;gt; [INFO] hadoop-yarn-server-tests ........................... SUCCESS [  3.772 s]
&amp;gt; [INFO] hadoop-yarn-client ................................. SUCCESS [  4.641 s]
&amp;gt; [INFO] hadoop-yarn-server-sharedcachemanager .............. SUCCESS [  2.433 s]
&amp;gt; [INFO] hadoop-yarn-applications ........................... SUCCESS [  0.019 s]
&amp;gt; [INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  1.884 s]
&amp;gt; [INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [  1.263 s]
&amp;gt; [INFO] hadoop-yarn-site ................................... SUCCESS [  0.020 s]
&amp;gt; [INFO] hadoop-yarn-registry ............................... SUCCESS [  3.532 s]
&amp;gt; [INFO] hadoop-yarn-project ................................ SUCCESS [  3.452 s]
&amp;gt; [INFO] hadoop-mapreduce-client ............................ SUCCESS [  0.036 s]
&amp;gt; [INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 15.195 s]
&amp;gt; [INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 12.459 s]
&amp;gt; [INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [  2.645 s]
&amp;gt; [INFO] hadoop-mapreduce-client-app ........................ SUCCESS [  6.342 s]
&amp;gt; [INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [  3.845 s]
&amp;gt; [INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 11.295 s]
&amp;gt; [INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  1.546 s]
&amp;gt; [INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  4.573 s]
&amp;gt; [INFO] hadoop-mapreduce ................................... SUCCESS [  2.164 s]
&amp;gt; [INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [  7.874 s]
&amp;gt; [INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [ 19.660 s]
&amp;gt; [INFO] Apache Hadoop Archives ............................. SUCCESS [  2.071 s]
&amp;gt; [INFO] Apache Hadoop Rumen ................................ SUCCESS [  3.966 s]
&amp;gt; [INFO] Apache Hadoop Gridmix .............................. SUCCESS [  3.215 s]
&amp;gt; [INFO] Apache Hadoop Data Join ............................ SUCCESS [  1.818 s]
&amp;gt; [INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [  1.478 s]
&amp;gt; [INFO] Apache Hadoop Extras ............................... SUCCESS [  2.037 s]
&amp;gt; [INFO] Apache Hadoop Pipes ................................ SUCCESS [  5.880 s]
&amp;gt; [INFO] Apache Hadoop OpenStack support .................... SUCCESS [  3.407 s]
&amp;gt; [INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [ 40.013 s]
&amp;gt; [INFO] Apache Hadoop Azure support ........................ SUCCESS [ 11.557 s]
&amp;gt; [INFO] Apache Hadoop Client ............................... SUCCESS [  7.659 s]
&amp;gt; [INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  0.042 s]
&amp;gt; [INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  3.072 s]
&amp;gt; [INFO] Apache Hadoop Tools Dist ........................... SUCCESS [  8.519 s]
&amp;gt; [INFO] Apache Hadoop Tools ................................ SUCCESS [  0.014 s]
&amp;gt; [INFO] Apache Hadoop Distribution ......................... SUCCESS [ 30.616 s]
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Total time: 29:26 min
&amp;gt; [INFO] Finished at: 2015-09-01T00:47:31+00:00
&amp;gt; [INFO] Final Memory: 224M/785M
&amp;gt; [INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para completar a compilação, executamos os testes, contudo, alguns deles podem apresentar falhas intermitentes (acontecem algumas vezes, outras não).&lt;/p&gt;

&lt;p&gt;Os testes podem levar algumas horas para rodar por completo.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mkdir hadoop-common-project/hadoop-common/target/test-classes/webapps/test

mvn test -Pnative -Drequire.snappy -Drequire.openssl -Dmaven.test.failure.ignore=true -Dsurefire.rerunFailingTestsCount=3

&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(alguns testes com falha intermitente)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;org.apache.hadoop.ipc.TestDecayRpcScheduler#testAccumulate&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics#testDataNodeTimeSpend&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache#testDataXceiverHandlesRequestShortCircuitShmFailure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;No final desse procedimento, o pacote do Hadoop estará gerado em:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Para copiar do container para a máquina host:
&lt;br/&gt;(&lt;code&gt;3cc2bc5e593b&lt;/code&gt; é o identificador do container no Docker)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# shell na máquina
sudo docker cp 3cc2bc5e593b:/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusão:ac8d87b01c866329a85ac2f7311bc677&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;Esse procedimento mostra como o Hadoop pode ser customizado para necessidades específicas e que não requer um esforço muito grande.&lt;/p&gt;

&lt;p&gt;Contudo, ter uma &amp;ldquo;versão&amp;rdquo; própria do Hadoop é uma decisão que deve ser tomada com cautela.&lt;/p&gt;

&lt;p&gt;No momento, a gente considera que essa seja a melhor escolha para o nosso trabalho na Globo.com e estamos querendo formar um time para evoluir e dar suporte a essa plataforma. O maior benefício é a liberdade de escolher como configurar e melhorar nossa infraestrutura. O custo é não ter uma empresa especializada &amp;ldquo;cuidando&amp;rdquo; dessa responsabilidade.&lt;/p&gt;

&lt;p&gt;No futuro, pode ser que mudemos esse modo de operação e busquemos uma distribuição &amp;ldquo;profissional&amp;rdquo; como Cloudera, Hortonworks ou outra.&lt;/p&gt;

&lt;p&gt;Particularmente, eu prefiro manter uma plataforma própria.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>